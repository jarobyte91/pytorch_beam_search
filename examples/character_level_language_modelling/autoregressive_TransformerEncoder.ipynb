{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tud\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "ï»¿The Project Gutenberg EBook of Chess Strategy, by Edward Lasker\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org/license\n",
      "\n",
      "\n",
      "Title: Chess Strategy\n",
      "\n",
      "Author: Edward Lasker\n",
      "\n",
      "Translator: J. Du Mont\n",
      "\n",
      "Release Date: November 11, 2012 [EBook #5614]\n",
      "\n",
      "Language: English\n",
      "\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK CHESS STRATEGY ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by John Mamoun <mamounjo@umdnj.edu>, Charles\n",
      "Franks, and the Online Distributed Proofreaders website.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INFORMATION ABOUT THIS E-TEXT EDITION\n",
      "\n",
      "\n",
      "\n",
      "The following is an e-text of \"Chess Strategy,\" second edition, (1915)\n",
      "by Edward Lasker, translated by J. Du Mont.\n",
      "\n",
      "This e-text contains the 167 chess and checkers board game\n",
      "diagrams appearing in the original book, all in the form of\n",
      "ASCII line drawings. The following is a key to the diagrams:\n",
      "\n",
      "For chess pieces\n"
     ]
    }
   ],
   "source": [
    "# chess\n",
    "\n",
    "with open(\"data/chess_book.txt\", encoding = \"utf-8\") as file:\n",
    "    text = file.read()\n",
    "print(len(text))\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556949"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(text)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2i = {c:i for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "char2i[\"<PAD>\"] = 0\n",
    "char2i[\"<START>\"] = 1\n",
    "char2i[\"<END>\"] = 2\n",
    "i2char = {i:c for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "i2char[0] = \"<PAD>\"\n",
    "i2char[1] = \"<START>\"\n",
    "i2char[2] = \"<END>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "556916\n",
      "['\\ufeffThe Project Gutenberg EBook of C', 'The Project Gutenberg EBook of Ch', 'he Project Gutenberg EBook of Che', 'e Project Gutenberg EBook of Ches', ' Project Gutenberg EBook of Chess']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc306ad20e1403f92a5eefdf1d7c601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=556916.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([556916, 33])\n"
     ]
    }
   ],
   "source": [
    "length = 33\n",
    "lines = []\n",
    "for i in range(len(text))[:-length]:\n",
    "    lines.append(text[i:length + i])\n",
    "print(len(text))\n",
    "print(len(lines))\n",
    "print(lines[:5])\n",
    "encoded = torch.tensor([[char2i[c] for c in l] for l in tqdm(lines)]).to(device).long()\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Max sequence length: 32\n",
      "Embedding dimension: 64\n",
      "Feedforward dimension: 256\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 164,255\n",
      "\n",
      "Epoch | Train                 | Training time\n",
      "      | Loss     | Error Rate |\n",
      "---------------------------------------------\n",
      "    1 |   1.7151 |     45.805 |         92.48\n",
      "    2 |   1.2631 |     36.594 |        186.35\n",
      "    3 |   1.1553 |     33.917 |        281.52\n",
      "    4 |   1.0972 |     32.520 |        382.42\n",
      "    5 |   1.0593 |     31.620 |        476.62\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.TransformerEncoder(char2i, i2char)\n",
    "net.to(device)\n",
    "performance = net.fit(encoded, save_path = \"checkpoints/autoregressive_transformer.pt\")\n",
    "net.save_architecture(\"architectures/autoregressive_transformer.architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Max sequence length: 32\n",
      "Embedding dimension: 64\n",
      "Feedforward dimension: 256\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 164,255\n",
      "\n",
      "tensor([ -9.2367,  -9.2016,  -8.1720,  -8.9351, -10.3069], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project Gutenberg-tm the pa',\n",
       " 'The Project Gutenberg-tm the paw',\n",
       " 'he Project Gutenberg-tm the pawn',\n",
       " \"e Project Gutenberg-tm the King'\",\n",
       " ' Project Gutenberg-tm the pawn a']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"architectures/autoregressive_transformer.architecture\")\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_transformer.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.greedy_search(encoded[:5, :12])\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Max sequence length: 32\n",
      "Embedding dimension: 64\n",
      "Feedforward dimension: 256\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 164,255\n",
      "\n",
      "tensor([-28.9927, -30.3730, -26.7802, -23.4505, -12.8352], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project Gutenbefforam,\\nand ',\n",
       " 'The Project procese, folllows to',\n",
       " 'he Project Game For B6ch, which\\n',\n",
       " 'e Project Gutenbernal for 12. ..',\n",
       " ' Project Gutenberg-tm the suppor']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"architectures/autoregressive_transformer.architecture\")\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_transformer.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.sample(encoded[:5, :12])\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Max sequence length: 32\n",
      "Embedding dimension: 64\n",
      "Feedforward dimension: 256\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 164,255\n",
      "\n",
      "tensor([[ -7.9266,  -8.1982,  -9.0614,  -9.2367,  -9.2722],\n",
      "        [ -7.8441,  -8.8582,  -9.2016,  -9.3110,  -9.6437],\n",
      "        [ -8.0777,  -9.2724,  -9.3451,  -9.4304,  -9.4867],\n",
      "        [ -8.2489,  -8.2498,  -9.3699,  -9.5252, -10.1802],\n",
      "        [ -9.1748,  -9.6040, -10.0753, -10.5528, -10.6235]], device='cuda:0')\n",
      "[['\\ufeffThe Project Gutenberg-tm of the',\n",
      "  '\\ufeffThe Project Gutenberg-tm 2. ...',\n",
      "  '\\ufeffThe Project Gutenberg-tm 2. P-K',\n",
      "  '\\ufeffThe Project Gutenberg-tm the pa',\n",
      "  '\\ufeffThe Project Gutenberg-tm 2. P-Q'],\n",
      " ['The Project Gutenberg-tm of the ',\n",
      "  'The Project Gutenberg-tm on the ',\n",
      "  'The Project Gutenberg-tm the paw',\n",
      "  'The Project Gutenberg-tm the Kin',\n",
      "  'The Project Gutenberg-tm with th'],\n",
      " ['he Project Gutenberg-tm 2. ...  ',\n",
      "  'he Project Gutenberg-tm 2. P-Q4 ',\n",
      "  'he Project Gutenberg-tm 2. P-QB4',\n",
      "  'he Project Gutenberg-tm 2. .... ',\n",
      "  'he Project Gutenberg-tm on the p'],\n",
      " ['e Project Gutenberg-tm with the ',\n",
      "  'e Project Gutenberg-tm therefore',\n",
      "  'e Project Gutenberg-tm on the pa',\n",
      "  'e Project Gutenberg-tm of the pa',\n",
      "  'e Project Gutenberg-tm on the Ki'],\n",
      " [' Project Gutenberg-tm 2. ...    ',\n",
      "  ' Project Gutenberg-tm 2. ... Kt-',\n",
      "  ' Project Gutenberg-tm 2. Kt-B3  ',\n",
      "  ' Project Gutenberg-tm 2. .. P-Kt',\n",
      "  ' Project Gutenberg-tm 2. ... Ktx']]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"architectures/autoregressive_transformer.architecture\")\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_transformer.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.beam_search(encoded[:5, :12])\n",
    "\n",
    "print(log_probabilities)\n",
    "pprint([net.tensor2text(t) for t in indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Max sequence length: 32\n",
      "Embedding dimension: 64\n",
      "Feedforward dimension: 256\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 164,255\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project Gutenberg-tm of the',\n",
       " 'The Project Gutenberg-tm of the ',\n",
       " 'he Project Gutenberg-tm 2. ...  ',\n",
       " 'e Project Gutenberg-tm with the ',\n",
       " ' Project Gutenberg-tm 2. ...    ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"architectures/autoregressive_transformer.architecture\")\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_transformer.pt\"))\n",
    "net.to(device)\n",
    "\n",
    "idx, log_probabilities = net.predict(encoded[:5, :12])\n",
    "\n",
    "net.tensor2text(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
