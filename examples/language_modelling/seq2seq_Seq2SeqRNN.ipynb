{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tud\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "ï»¿The Project Gutenberg EBook of Chess Strategy, by Edward Lasker\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org/license\n",
      "\n",
      "\n",
      "Title: Chess Strategy\n",
      "\n",
      "Author: Edward Lasker\n",
      "\n",
      "Translator: J. Du Mont\n",
      "\n",
      "Release Date: November 11, 2012 [EBook #5614]\n",
      "\n",
      "Language: English\n",
      "\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK CHESS STRATEGY ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by John Mamoun <mamounjo@umdnj.edu>, Charles\n",
      "Franks, and the Online Distributed Proofreaders website.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INFORMATION ABOUT THIS E-TEXT EDITION\n",
      "\n",
      "\n",
      "\n",
      "The following is an e-text of \"Chess Strategy,\" second edition, (1915)\n",
      "by Edward Lasker, translated by J. Du Mont.\n",
      "\n",
      "This e-text contains the 167 chess and checkers board game\n",
      "diagrams appearing in the original book, all in the form of\n",
      "ASCII line drawings. The following is a key to the diagrams:\n",
      "\n",
      "For chess pieces\n"
     ]
    }
   ],
   "source": [
    "# chess\n",
    "\n",
    "with open(\"data/chess_book.txt\", encoding = \"utf-8\") as file:\n",
    "    text = file.read()\n",
    "print(len(text))\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556949"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(text)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "char2i = {c:i for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "char2i[\"<PAD>\"] = 0\n",
    "char2i[\"<START>\"] = 1\n",
    "char2i[\"<END>\"] = 2\n",
    "print(len(char2i))\n",
    "i2char = {i:c for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "i2char[0] = \"<PAD>\"\n",
    "i2char[1] = \"<START>\"\n",
    "i2char[2] = \"<END>\"\n",
    "print(len(i2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "556929\n",
      "['\\ufeffThe Project Gutenbe', 'The Project Gutenber', 'he Project Gutenberg', 'e Project Gutenberg ', ' Project Gutenberg E']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32323128f19045968a7d414afd51d5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=556929.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([556929, 20])\n",
      "torch.Size([556929, 10])\n",
      "torch.Size([556929, 11])\n"
     ]
    }
   ],
   "source": [
    "length = 20\n",
    "lines = []\n",
    "for i in range(len(text))[:-length]:\n",
    "    lines.append(text[i:length + i])\n",
    "print(len(text))\n",
    "print(len(lines))\n",
    "print(lines[:5])\n",
    "encoded = torch.tensor([[char2i[c] for c in l] for l in tqdm(lines)]).to(device).long()\n",
    "print(encoded.shape)\n",
    "source_1 = encoded[:, :length // 2]\n",
    "print(source_1.shape)\n",
    "target_1 = torch.cat((torch.ones(encoded.shape[0], 1).to(device).long(), encoded[:, length // 2:]), axis = 1)\n",
    "print(target_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq RNN\n",
      "Tokens in the input vocabulary: 95\n",
      "Tokens in the output vocabulary: 95\n",
      "In embedding dimension: 8\n",
      "Out embedding dimension: 8\n",
      "Encoder hidden units: 32\n",
      "Encoder layers: 2\n",
      "Decoder hidden units: 32\n",
      "Decoder layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 40,495\n",
      "\n",
      "Epoch | Train                 | Training time\n",
      "      | Loss     | Error Rate |\n",
      "---------------------------------------------\n",
      "    1 |   3.0202 |     70.035 |         37.28\n",
      "    2 |   2.1847 |     55.512 |         74.30\n",
      "    3 |   1.8134 |     48.153 |        114.33\n",
      "    4 |   1.6475 |     44.843 |        154.92\n",
      "    5 |   1.5552 |     43.085 |        193.19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_error_rate</th>\n",
       "      <th>training_time</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>model</th>\n",
       "      <th>in_embedding_dimension</th>\n",
       "      <th>out_embedding_dimension</th>\n",
       "      <th>encoder_hidden_units</th>\n",
       "      <th>encoder_layers</th>\n",
       "      <th>decoder_hidden_units</th>\n",
       "      <th>decoder_layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.020154</td>\n",
       "      <td>70.035337</td>\n",
       "      <td>37.283324</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Seq2Seq RNN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.184674</td>\n",
       "      <td>55.511870</td>\n",
       "      <td>74.295685</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Seq2Seq RNN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.813378</td>\n",
       "      <td>48.153104</td>\n",
       "      <td>114.333292</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Seq2Seq RNN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.647490</td>\n",
       "      <td>44.843041</td>\n",
       "      <td>154.919591</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Seq2Seq RNN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.555250</td>\n",
       "      <td>43.084522</td>\n",
       "      <td>193.194491</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Seq2Seq RNN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_error_rate  training_time  learning_rate  \\\n",
       "0      1    3.020154         70.035337      37.283324         0.0001   \n",
       "1      2    2.184674         55.511870      74.295685         0.0001   \n",
       "2      3    1.813378         48.153104     114.333292         0.0001   \n",
       "3      4    1.647490         44.843041     154.919591         0.0001   \n",
       "4      5    1.555250         43.084522     193.194491         0.0001   \n",
       "\n",
       "   weight_decay        model  in_embedding_dimension  out_embedding_dimension  \\\n",
       "0             0  Seq2Seq RNN                       8                        8   \n",
       "1             0  Seq2Seq RNN                       8                        8   \n",
       "2             0  Seq2Seq RNN                       8                        8   \n",
       "3             0  Seq2Seq RNN                       8                        8   \n",
       "4             0  Seq2Seq RNN                       8                        8   \n",
       "\n",
       "   encoder_hidden_units  encoder_layers  decoder_hidden_units  decoder_layers  \\\n",
       "0                    32               2                    32               2   \n",
       "1                    32               2                    32               2   \n",
       "2                    32               2                    32               2   \n",
       "3                    32               2                    32               2   \n",
       "4                    32               2                    32               2   \n",
       "\n",
       "   dropout  parameters  \n",
       "0      0.0       40495  \n",
       "1      0.0       40495  \n",
       "2      0.0       40495  \n",
       "3      0.0       40495  \n",
       "4      0.0       40495  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.Seq2SeqRNN(char2i, i2char)\n",
    "net.to(device)\n",
    "net.fit(source_1, target_1, save_path = \"checkpoints/seq2seq_rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq RNN\n",
      "Tokens in the input vocabulary: 95\n",
      "Tokens in the output vocabulary: 95\n",
      "In embedding dimension: 8\n",
      "Out embedding dimension: 8\n",
      "Encoder hidden units: 32\n",
      "Encoder layers: 2\n",
      "Decoder hidden units: 32\n",
      "Decoder layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 40,495\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['<START> the the the the the',\n",
       "  '<START> the the the the to ',\n",
       "  '<START>s the the the the th',\n",
       "  '<START> the the the the Kt-',\n",
       "  '<START> the the the the thi'],\n",
       " ['<START> the the the the the',\n",
       "  '<START>e the the the the th',\n",
       "  '<START>e the the the the to',\n",
       "  '<START>e the the the the pa',\n",
       "  '<START>e the the the the Kt'],\n",
       " ['<START>ing the the the the ',\n",
       "  '<START>hite the the the the',\n",
       "  '<START>he the the the the t',\n",
       "  '<START>er the the the the t',\n",
       "  '<START>hite the the the to '],\n",
       " ['<START>the the the the the ',\n",
       "  '<START>the the the the and ',\n",
       "  '<START>the the Black the th',\n",
       "  '<START>the the the the Kt-K',\n",
       "  '<START>the the the the Kt-Q'],\n",
       " ['<START>. Kt-K4, the the the',\n",
       "  '<START>. Kt-B3, the the the',\n",
       "  '<START>. Kt-K4, the the Kt-',\n",
       "  '<START>. Kt-B3, the the Kt-',\n",
       "  '<START>. Kt-K4, the the to ']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.Seq2SeqRNN(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/seq2seq_rnn.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.beam_search(source_1[:5])\n",
    "\n",
    "[net.tensor2text(t) for t in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq RNN\n",
      "Tokens in the input vocabulary: 95\n",
      "Tokens in the output vocabulary: 95\n",
      "In embedding dimension: 8\n",
      "Out embedding dimension: 8\n",
      "Encoder hidden units: 32\n",
      "Encoder layers: 2\n",
      "Decoder hidden units: 32\n",
      "Decoder layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 40,495\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<START>n sins as uvere colf',\n",
       " '<START> mowecey at in Q. Bx',\n",
       " '<START>is cows\\nQiSt iy the ',\n",
       " '<START>harotg hp.\\n\\n        ',\n",
       " '<START>. B-K2\\n, Kt-K1; BxP,']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.Seq2SeqRNN(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/seq2seq_rnn.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.sample(source_1[:5])\n",
    "\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
