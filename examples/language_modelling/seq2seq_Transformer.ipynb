{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tud\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "ï»¿The Project Gutenberg EBook of Chess Strategy, by Edward Lasker\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org/license\n",
      "\n",
      "\n",
      "Title: Chess Strategy\n",
      "\n",
      "Author: Edward Lasker\n",
      "\n",
      "Translator: J. Du Mont\n",
      "\n",
      "Release Date: November 11, 2012 [EBook #5614]\n",
      "\n",
      "Language: English\n",
      "\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK CHESS STRATEGY ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by John Mamoun <mamounjo@umdnj.edu>, Charles\n",
      "Franks, and the Online Distributed Proofreaders website.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INFORMATION ABOUT THIS E-TEXT EDITION\n",
      "\n",
      "\n",
      "\n",
      "The following is an e-text of \"Chess Strategy,\" second edition, (1915)\n",
      "by Edward Lasker, translated by J. Du Mont.\n",
      "\n",
      "This e-text contains the 167 chess and checkers board game\n",
      "diagrams appearing in the original book, all in the form of\n",
      "ASCII line drawings. The following is a key to the diagrams:\n",
      "\n",
      "For chess pieces\n"
     ]
    }
   ],
   "source": [
    "# chess\n",
    "\n",
    "with open(\"data/chess_book.txt\", encoding = \"utf-8\") as file:\n",
    "    text = file.read()\n",
    "print(len(text))\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556949"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(text)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "char2i = {c:i for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "char2i[\"<PAD>\"] = 0\n",
    "char2i[\"<START>\"] = 1\n",
    "char2i[\"<END>\"] = 2\n",
    "print(len(char2i))\n",
    "i2char = {i:c for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "i2char[0] = \"<PAD>\"\n",
    "i2char[1] = \"<START>\"\n",
    "i2char[2] = \"<END>\"\n",
    "print(len(i2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "556929\n",
      "['\\ufeffThe Project Gutenbe', 'The Project Gutenber', 'he Project Gutenberg', 'e Project Gutenberg ', ' Project Gutenberg E']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cb67c0d67f4a8f8760b82f5f07abdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=556929.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([556929, 20])\n",
      "torch.Size([556929, 10])\n",
      "torch.Size([556929, 11])\n"
     ]
    }
   ],
   "source": [
    "length = 20\n",
    "lines = []\n",
    "for i in range(len(text))[:-length]:\n",
    "    lines.append(text[i:length + i])\n",
    "print(len(text))\n",
    "print(len(lines))\n",
    "print(lines[:5])\n",
    "encoded = torch.tensor([[char2i[c] for c in l] for l in tqdm(lines)]).to(device).long()\n",
    "print(encoded.shape)\n",
    "source_1 = encoded[:, :length // 2]\n",
    "print(source_1.shape)\n",
    "target_1 = torch.cat((torch.ones(encoded.shape[0], 1).to(device).long(), encoded[:, length // 2:]), axis = 1)\n",
    "print(target_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Transformer\n",
      "Tokens in the input vocabulary: 95\n",
      "Tokens in the output vocabulary: 95\n",
      "Embedding dimension: 8\n",
      "Feedforward dimension: 32\n",
      "Encoder layers: 2\n",
      "Decoder layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 6,759\n",
      "\n",
      "Epoch | Train                 | Training time\n",
      "      | Loss     | Error Rate |\n",
      "---------------------------------------------\n",
      "    1 |   2.8016 |     61.004 |        112.50\n",
      "    2 |   2.1414 |     55.147 |        226.57\n",
      "    3 |   1.9693 |     52.035 |        349.77\n",
      "    4 |   1.8914 |     50.299 |        459.14\n",
      "    5 |   1.8468 |     49.378 |        571.56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_error_rate</th>\n",
       "      <th>training_time</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>model</th>\n",
       "      <th>embedding_dimension</th>\n",
       "      <th>feedforward_dimension</th>\n",
       "      <th>encoder_layers</th>\n",
       "      <th>decoder_layers</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.801586</td>\n",
       "      <td>61.003737</td>\n",
       "      <td>112.498123</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.141373</td>\n",
       "      <td>55.146563</td>\n",
       "      <td>226.566216</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.969328</td>\n",
       "      <td>52.034820</td>\n",
       "      <td>349.772037</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.891375</td>\n",
       "      <td>50.299033</td>\n",
       "      <td>459.136350</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.846799</td>\n",
       "      <td>49.378072</td>\n",
       "      <td>571.563894</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_error_rate  training_time  learning_rate  \\\n",
       "0      1    2.801586         61.003737     112.498123         0.0001   \n",
       "1      2    2.141373         55.146563     226.566216         0.0001   \n",
       "2      3    1.969328         52.034820     349.772037         0.0001   \n",
       "3      4    1.891375         50.299033     459.136350         0.0001   \n",
       "4      5    1.846799         49.378072     571.563894         0.0001   \n",
       "\n",
       "   weight_decay        model  embedding_dimension  feedforward_dimension  \\\n",
       "0             0  Transformer                    8                     32   \n",
       "1             0  Transformer                    8                     32   \n",
       "2             0  Transformer                    8                     32   \n",
       "3             0  Transformer                    8                     32   \n",
       "4             0  Transformer                    8                     32   \n",
       "\n",
       "   encoder_layers  decoder_layers  attention_heads activation  dropout  \\\n",
       "0               2               2                2       relu      0.0   \n",
       "1               2               2                2       relu      0.0   \n",
       "2               2               2                2       relu      0.0   \n",
       "3               2               2                2       relu      0.0   \n",
       "4               2               2                2       relu      0.0   \n",
       "\n",
       "   parameters  \n",
       "0        6759  \n",
       "1        6759  \n",
       "2        6759  \n",
       "3        6759  \n",
       "4        6759  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.Transformer(char2i, i2char)\n",
    "net.to(device)\n",
    "net.fit(source_1, target_1, save_path = \"checkpoints/seq2seq_transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Transformer\n",
      "Tokens in the input vocabulary: 95\n",
      "Tokens in the output vocabulary: 95\n",
      "Embedding dimension: 8\n",
      "Feedforward dimension: 32\n",
      "Encoder layers: 2\n",
      "Decoder layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 6,759\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['<START>s the the the  th th',\n",
       "  '<START>s the the the  tt th',\n",
       "  '<START>s the the the  th he',\n",
       "  '<START>s the the the  tt he',\n",
       "  '<START>s the the the  th at'],\n",
       " ['<START> the te the the t th',\n",
       "  '<START> the te the the t at',\n",
       "  '<START> the te the the t\\n t',\n",
       "  '<START> the te the then het',\n",
       "  '<START> the te the the chet'],\n",
       " ['<START> the te the the t th',\n",
       "  '<START> the te the the t at',\n",
       "  '<START> the te the the t\\n t',\n",
       "  '<START> the te the the t\\n  ',\n",
       "  '<START> the te the the  het'],\n",
       " ['<START>the the the the t th',\n",
       "  '<START>the the the the athe',\n",
       "  '<START>the the the the  het',\n",
       "  '<START>the the the the atho',\n",
       "  '<START>the the the the  hes'],\n",
       " ['<START>the the the the t th',\n",
       "  '<START>the the the the  het',\n",
       "  '<START>the the the the t\\n t',\n",
       "  '<START>the the the the t\\n  ',\n",
       "  '<START>the the the the  hes']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.Transformer(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/seq2seq_transformer.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.beam_search(source_1[:5])\n",
    "\n",
    "[net.tensor2text(t) for t in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Transformer\n",
      "Tokens in the input vocabulary: 95\n",
      "Tokens in the output vocabulary: 95\n",
      "Embedding dimension: 8\n",
      "Feedforward dimension: 32\n",
      "Encoder layers: 2\n",
      "Decoder layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 6,759\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<START>\\n\\nTrcatonicarsotuck.',\n",
       " \"<START>gafir of s'kos fv ov\",\n",
       " '<START>ged P-f. Ehifiecmede',\n",
       " '<START>amvifi Whafbe o. t;o',\n",
       " '<START>an te\\nlosevonehwos Q']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.Transformer(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/seq2seq_transformer.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.sample(source_1[:5])\n",
    "\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
