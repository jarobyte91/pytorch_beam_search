{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tud\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "ï»¿The Project Gutenberg EBook of Chess Strategy, by Edward Lasker\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org/license\n",
      "\n",
      "\n",
      "Title: Chess Strategy\n",
      "\n",
      "Author: Edward Lasker\n",
      "\n",
      "Translator: J. Du Mont\n",
      "\n",
      "Release Date: November 11, 2012 [EBook #5614]\n",
      "\n",
      "Language: English\n",
      "\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK CHESS STRATEGY ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by John Mamoun <mamounjo@umdnj.edu>, Charles\n",
      "Franks, and the Online Distributed Proofreaders website.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INFORMATION ABOUT THIS E-TEXT EDITION\n",
      "\n",
      "\n",
      "\n",
      "The following is an e-text of \"Chess Strategy,\" second edition, (1915)\n",
      "by Edward Lasker, translated by J. Du Mont.\n",
      "\n",
      "This e-text contains the 167 chess and checkers board game\n",
      "diagrams appearing in the original book, all in the form of\n",
      "ASCII line drawings. The following is a key to the diagrams:\n",
      "\n",
      "For chess pieces\n"
     ]
    }
   ],
   "source": [
    "# chess\n",
    "\n",
    "with open(\"data/chess_book.txt\", encoding = \"utf-8\") as file:\n",
    "    text = file.read()\n",
    "print(len(text))\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556949"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(text)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2i = {c:i for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "char2i[\"<PAD>\"] = 0\n",
    "char2i[\"<START>\"] = 1\n",
    "char2i[\"<END>\"] = 2\n",
    "i2char = {i:c for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "i2char[0] = \"<PAD>\"\n",
    "i2char[1] = \"<START>\"\n",
    "i2char[2] = \"<END>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "556916\n",
      "['\\ufeffThe Project Gutenberg EBook of C', 'The Project Gutenberg EBook of Ch', 'he Project Gutenberg EBook of Che', 'e Project Gutenberg EBook of Ches', ' Project Gutenberg EBook of Chess']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49772b3d1f44834a9ad9339f5da1d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=556916.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([556916, 33])\n"
     ]
    }
   ],
   "source": [
    "length = 33\n",
    "lines = []\n",
    "for i in range(len(text))[:-length]:\n",
    "    lines.append(text[i:length + i])\n",
    "print(len(text))\n",
    "print(len(lines))\n",
    "print(lines[:5])\n",
    "encoded = torch.tensor([[char2i[c] for c in l] for l in tqdm(lines)]).to(device).long()\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Max sequence length: 32\n",
      "Embedding dimension: 32\n",
      "Feedforward dimension: 128\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 45,311\n",
      "\n",
      "Epoch | Train                 | Development           | Training time\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------------\n",
      "    1 |   2.1008 |     53.381 |   3.1091 |     76.778 |         78.23\n",
      "    2 |   1.5755 |     44.286 |   2.9905 |     74.178 |        153.83\n",
      "    3 |   1.4174 |     40.473 |   2.8962 |     72.456 |        228.42\n",
      "    4 |   1.3301 |     38.326 |   2.8123 |     70.347 |        301.76\n",
      "    5 |   1.2726 |     36.896 |   2.7413 |     69.388 |        378.12\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.TransformerEncoder(char2i, i2char)\n",
    "net.to(device)\n",
    "# using a subsample as \"dev\" set\n",
    "performance = net.fit(encoded, encoded[:1000], save_path = \"checkpoints/autoregressive_transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Max sequence length: 32\n",
      "Embedding dimension: 32\n",
      "Feedforward dimension: 128\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 45,311\n",
      "\n",
      "tensor([-17.3235, -17.3223, -17.8486, -15.1379, -17.0083], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project of the play the paw',\n",
       " 'The Project the pawn an the pawn',\n",
       " 'he Project Gut the play the pawn',\n",
       " 'e Project Gut the pawn the pawn ',\n",
       " ' Project Gut the pawn the play t']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.TransformerEncoder(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_transformer.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.greedy_search(encoded[:5, :12])\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Max sequence length: 32\n",
      "Embedding dimension: 32\n",
      "Feedforward dimension: 128\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 45,311\n",
      "\n",
      "tensor([-35.4042, -37.3997, -38.7031, -39.0357, -51.5738], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project\\nof removerate a pos',\n",
       " 'The Project coning the or thotk.',\n",
       " 'he Project Guagre al ady would Q',\n",
       " 'e Project Gurse me precculy be t',\n",
       " ' Project Gut sijelence iticaugti']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.TransformerEncoder(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_transformer.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.sample(encoded[:5, :12])\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Max sequence length: 32\n",
      "Embedding dimension: 32\n",
      "Feedforward dimension: 128\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 45,311\n",
      "\n",
      "tensor([[-12.3343, -14.5509, -15.1686, -15.4284, -15.7189],\n",
      "        [-14.2857, -14.3190, -14.7305, -15.1044, -15.2126],\n",
      "        [-14.9410, -15.0016, -16.4287, -16.5968, -16.8477],\n",
      "        [-15.1379, -15.1908, -15.6329, -16.5546, -16.5848],\n",
      "        [-12.7563, -15.0439, -15.6290, -15.8614, -16.1553]], device='cuda:0')\n",
      "[['\\ufeffThe Project of the King.\\n\\n     ',\n",
      "  \"\\ufeffThe Project of the King's of th\",\n",
      "  \"\\ufeffThe Project of the King's the p\",\n",
      "  \"\\ufeffThe Project of the King's the K\",\n",
      "  \"\\ufeffThe Project of the King's the t\"],\n",
      " ['The Project of the the pawn the ',\n",
      "  \"The Project of the King's of the\",\n",
      "  \"The Project of the King's the mo\",\n",
      "  \"The Project of the King's the pa\",\n",
      "  \"The Project of the King's the pr\"],\n",
      " [\"he Project Gut of the the King's\",\n",
      "  'he Project Gut the the pawn the ',\n",
      "  'he Project Gut of the the King t',\n",
      "  'he Project Gut of the the Queen ',\n",
      "  \"he Project Gut of the the Queen'\"],\n",
      " ['e Project Gut the pawn the pawn ',\n",
      "  'e Project Gut the pawn the King ',\n",
      "  \"e Project Gut the pawn the King'\",\n",
      "  'e Project Gut of the pawn the pa',\n",
      "  'e Project Gut the pawn the pawns'],\n",
      " [' Project Gut of the King.\\n\\n     ',\n",
      "  \" Project Gut of the King's of th\",\n",
      "  \" Project Gut of the King's the p\",\n",
      "  \" Project Gut of the King's the K\",\n",
      "  \" Project Gut of the King's the Q\"]]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.TransformerEncoder(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_transformer.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.beam_search(encoded[:5, :12])\n",
    "\n",
    "print(log_probabilities)\n",
    "pprint([net.tensor2text(t) for t in indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project of the King.\\n\\n     ',\n",
       " 'The Project of the the pawn the ',\n",
       " \"he Project Gut of the the King's\",\n",
       " 'e Project Gut the pawn the pawn ',\n",
       " ' Project Gut of the King.\\n\\n     ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, log_probabilities = net.predict(encoded[:5, :12])\n",
    "\n",
    "net.tensor2text(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
