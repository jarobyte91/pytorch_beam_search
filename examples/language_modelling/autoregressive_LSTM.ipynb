{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tud\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "ï»¿The Project Gutenberg EBook of Chess Strategy, by Edward Lasker\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org/license\n",
      "\n",
      "\n",
      "Title: Chess Strategy\n",
      "\n",
      "Author: Edward Lasker\n",
      "\n",
      "Translator: J. Du Mont\n",
      "\n",
      "Release Date: November 11, 2012 [EBook #5614]\n",
      "\n",
      "Language: English\n",
      "\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK CHESS STRATEGY ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by John Mamoun <mamounjo@umdnj.edu>, Charles\n",
      "Franks, and the Online Distributed Proofreaders website.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INFORMATION ABOUT THIS E-TEXT EDITION\n",
      "\n",
      "\n",
      "\n",
      "The following is an e-text of \"Chess Strategy,\" second edition, (1915)\n",
      "by Edward Lasker, translated by J. Du Mont.\n",
      "\n",
      "This e-text contains the 167 chess and checkers board game\n",
      "diagrams appearing in the original book, all in the form of\n",
      "ASCII line drawings. The following is a key to the diagrams:\n",
      "\n",
      "For chess pieces\n"
     ]
    }
   ],
   "source": [
    "# chess\n",
    "\n",
    "with open(\"data/chess_book.txt\", encoding = \"utf-8\") as file:\n",
    "    text = file.read()\n",
    "print(len(text))\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556949"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(text)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2i = {c:i for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "char2i[\"<PAD>\"] = 0\n",
    "char2i[\"<START>\"] = 1\n",
    "char2i[\"<END>\"] = 2\n",
    "i2char = {i:c for i, c in enumerate(sorted(vocabulary), 3)}\n",
    "i2char[0] = \"<PAD>\"\n",
    "i2char[1] = \"<START>\"\n",
    "i2char[2] = \"<END>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556949\n",
      "556928\n",
      "['\\ufeffThe Project Gutenber', 'The Project Gutenberg', 'he Project Gutenberg ', 'e Project Gutenberg E', ' Project Gutenberg EB']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc67b80a0cd74dcc8684991a5b7b5771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=556928.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([556928, 21])\n"
     ]
    }
   ],
   "source": [
    "length = 21\n",
    "lines = []\n",
    "for i in range(len(text))[:-length]:\n",
    "    lines.append(text[i:length + i])\n",
    "print(len(text))\n",
    "print(len(lines))\n",
    "print(lines[:5])\n",
    "encoded = torch.tensor([[char2i[c] for c in l] for l in tqdm(lines)]).to(device).long()\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Embedding dimension: 8\n",
      "Hidden units: 64\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 59,159\n",
      "\n",
      "Epoch | Train                 | Development           | Training time\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------------\n",
      "    1 |   2.4601 |     59.684 |   3.3709 |     78.035 |         36.92\n",
      "    2 |   1.7527 |     46.546 |   3.1164 |     73.575 |         73.44\n",
      "    3 |   1.5131 |     41.576 |   2.9371 |     72.200 |        109.67\n",
      "    4 |   1.3859 |     38.736 |   2.8369 |     70.275 |        146.38\n",
      "    5 |   1.3098 |     36.965 |   2.7619 |     67.345 |        183.49\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.LSTM(char2i, i2char)\n",
    "net.to(device)\n",
    "# using a subsample as \"dev\" set\n",
    "performance = net.fit(encoded, encoded[:1000], save_path = \"checkpoints/autoregressive_lstm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Embedding dimension: 8\n",
      "Hidden units: 64\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 59,159\n",
      "\n",
      "tensor([-19.5982, -18.1931, -16.9650, -19.1240, -19.1656], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project Gutenberg the pawn at the pa',\n",
       " 'The Project Gutenberg the pawn at the paw',\n",
       " 'he Project Gutenberg the pawn at the pawn',\n",
       " 'e Project Gutenberg Eom the pawn at the p',\n",
       " ' Project Gutenberg EB           Kt-Kt3\\n  ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.LSTM(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_lstm.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.greedy_search(encoded[:5])\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Embedding dimension: 8\n",
      "Hidden units: 64\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 59,159\n",
      "\n",
      "tensor([-36.9407, -31.6861, -37.3709, -28.8181, -34.5342], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project Gutenbernevile fing, and mov',\n",
       " 'The Project Gutenbergs there\\nevent-game o',\n",
       " 'he Project Gutenberg weorr to whes\\n\\n     ',\n",
       " 'e Project Gutenberg Eefenced with other m',\n",
       " ' Project Gutenberg EBare collition, oved ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.LSTM(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_lstm.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.sample(encoded[:5])\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the in vocabulary: 95\n",
      "Tokens in the out vocabulary: 95\n",
      "Embedding dimension: 8\n",
      "Hidden units: 64\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 59,159\n",
      "\n",
      "tensor([[-16.8889, -17.8440, -17.8571, -18.0461, -18.2158],\n",
      "        [ -6.7699,  -8.4641, -10.2892, -10.7763, -10.7949],\n",
      "        [-15.4294, -15.6800, -15.9391, -16.1423, -16.2700],\n",
      "        [-16.0051, -16.0439, -16.2139, -16.4134, -16.5486],\n",
      "        [ -5.3734,  -6.8448,  -7.3414, -11.5521, -12.0292]], device='cuda:0')\n",
      "[['\\ufeffThe Project Gutenberation the pawns the ',\n",
      "  \"\\ufeffThe Project Gutenberations the King's of\",\n",
      "  \"\\ufeffThe Project Gutenberations the King's th\",\n",
      "  \"\\ufeffThe Project Gutenberations the King's an\",\n",
      "  \"\\ufeffThe Project Gutenberations the King's to\"],\n",
      " ['The Project Gutenberg.\\n\\n        ---------',\n",
      "  'The Project Gutenberg.\\n\\n                 ',\n",
      "  'The Project Gutenberg.\\n\\n          2. Kt-K',\n",
      "  'The Project Gutenberg.\\n\\n          2. Kt-Q',\n",
      "  'The Project Gutenberg.\\n\\n          2. Kt-B'],\n",
      " ['he Project Gutenberg the pawn of the pawn',\n",
      "  \"he Project Gutenberg the King's of the pa\",\n",
      "  \"he Project Gutenberg the King's and the p\",\n",
      "  \"he Project Gutenberg the King's of the Ki\",\n",
      "  \"he Project Gutenberg the King's and the K\"],\n",
      " [\"e Project Gutenberg Eove of the King's of\",\n",
      "  \"e Project Gutenberg Eove of the King's th\",\n",
      "  \"e Project Gutenberg Eove of the King's an\",\n",
      "  \"e Project Gutenberg Eove of the King's to\",\n",
      "  'e Project Gutenberg Eove of the pawn of t'],\n",
      " [' Project Gutenberg EB\\n        -----------',\n",
      "  ' Project Gutenberg EB\\n         ----------',\n",
      "  ' Project Gutenberg EB\\n       ------------',\n",
      "  ' Project Gutenberg EB\\n        ----------\\n',\n",
      "  ' Project Gutenberg EB\\n                   ']]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.LSTM(char2i, i2char)\n",
    "net.load_state_dict(torch.load(\"checkpoints/autoregressive_lstm.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.beam_search(encoded[:5])\n",
    "\n",
    "print(log_probabilities)\n",
    "pprint([net.tensor2text(t) for t in indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\ufeffThe Project Gutenberations the King's of \",\n",
       " 'The Project Gutenberg.\\n\\n        ----------',\n",
       " 'he Project Gutenberg the pawn of the pawn ',\n",
       " \"e Project Gutenberg Eove of the King's of \",\n",
       " ' Project Gutenberg EB\\n        ------------']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, log_probabilities = net.predict(encoded[:5])\n",
    "\n",
    "net.tensor2text(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
