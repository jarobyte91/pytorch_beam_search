{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cead063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tud\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5a60b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556948\n",
      "The Project Gutenberg EBook of Chess Strategy, by Edward Lasker\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org/license\n",
      "\n",
      "\n",
      "Title: Chess Strategy\n",
      "\n",
      "Author: Edward Lasker\n",
      "\n",
      "Translator: J. Du Mont\n",
      "\n",
      "Release Date: November 11, 2012 [EBook #5614]\n",
      "\n",
      "Language: English\n",
      "\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK CHESS STRATEGY ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by John Mamoun <mamounjo@umdnj.edu>, Charles\n",
      "Franks, and the Online Distributed Proofreaders website.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INFORMATION ABOUT THIS E-TEXT EDITION\n",
      "\n",
      "\n",
      "\n",
      "The following is an e-text of \"Chess Strategy,\" second edition, (1915)\n",
      "by Edward Lasker, translated by J. Du Mont.\n",
      "\n",
      "This e-text contains the 167 chess and checkers board game\n",
      "diagrams appearing in the original book, all in the form of\n",
      "ASCII line drawings. The following is a key to the diagrams:\n",
      "\n",
      "For chess pieces,\n"
     ]
    }
   ],
   "source": [
    "# chess\n",
    "\n",
    "with open(\"chess_book.txt\", encoding = \"utf-8\") as file:\n",
    "    text = file.read()\n",
    "print(len(text))\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a531a84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556948"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c17640f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(text)\n",
    "\n",
    "# from collections import Counter\n",
    "# vocabulary = Counter(text)\n",
    "\n",
    "# from nltk.lm import Vocabulary\n",
    "# vocabulary = Vocabulary(text)\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2325bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "680b1ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556948\n",
      "556931\n",
      "['The Project Guten', 'he Project Gutenb', 'e Project Gutenbe', ' Project Gutenber', 'Project Gutenberg']\n"
     ]
    }
   ],
   "source": [
    "length = 17\n",
    "lines = []\n",
    "for i in range(len(text))[:-length]:\n",
    "    lines.append(text[i:length + i])\n",
    "print(len(text))\n",
    "print(len(lines))\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ff33d",
   "metadata": {},
   "source": [
    "# fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7550ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the vocabulary: 91\n",
      "Embedding dimension: 32\n",
      "Hidden units: 128\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 229,852\n",
      "\n",
      "encoded torch.Size([556931, 17])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed59931907804878bec4c56066199fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Epochs: 5\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0\n",
      "Epoch | Train                 | Minutes\n",
      "      | Loss     | Error Rate |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209fc12e4a334dd8b87a8ccd99257f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 |   1.9663 |     49.577 |     0.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1257cc2361b84a0b88315281bcc0171c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 |   1.3551 |     37.738 |     1.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ab99899dff4c89852071171a53f9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3 |   1.2150 |     34.651 |     2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ad2768c9334f84af7f9008c54bc740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 |   1.1435 |     32.968 |     2.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6077581f07434535b86d365b8f18214d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 |   1.0969 |     31.873 |     3.2\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.LSTM(vocabulary)\n",
    "# net = autoregressive.TransformerEncoder(vocabulary)\n",
    "net.to(device)\n",
    "\n",
    "encoded = net.text2tensor(lines)\n",
    "print(\"encoded\", encoded.shape)\n",
    "\n",
    "performance = net.fit(encoded, save_path = \"model.pt\")\n",
    "net.save_architecture(\"model.arch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bce5ac70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_error_rate</th>\n",
       "      <th>training_minutes</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>model</th>\n",
       "      <th>embedding_dimension</th>\n",
       "      <th>hidden_units</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.966324</td>\n",
       "      <td>49.577461</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive LSTM</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.355083</td>\n",
       "      <td>37.738236</td>\n",
       "      <td>1.301947</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive LSTM</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.215004</td>\n",
       "      <td>34.650601</td>\n",
       "      <td>1.950478</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive LSTM</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.143546</td>\n",
       "      <td>32.967594</td>\n",
       "      <td>2.597870</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive LSTM</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.096932</td>\n",
       "      <td>31.873248</td>\n",
       "      <td>3.245812</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive LSTM</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_error_rate  training_minutes  learning_rate  \\\n",
       "0      1    1.966324         49.577461          0.649485         0.0001   \n",
       "1      2    1.355083         37.738236          1.301947         0.0001   \n",
       "2      3    1.215004         34.650601          1.950478         0.0001   \n",
       "3      4    1.143546         32.967594          2.597870         0.0001   \n",
       "4      5    1.096932         31.873248          3.245812         0.0001   \n",
       "\n",
       "   weight_decay                model  embedding_dimension  hidden_units  \\\n",
       "0             0  Autoregressive LSTM                   32           128   \n",
       "1             0  Autoregressive LSTM                   32           128   \n",
       "2             0  Autoregressive LSTM                   32           128   \n",
       "3             0  Autoregressive LSTM                   32           128   \n",
       "4             0  Autoregressive LSTM                   32           128   \n",
       "\n",
       "   layers  dropout  parameters  \n",
       "0       2      0.0      229852  \n",
       "1       2      0.0      229852  \n",
       "2       2      0.0      229852  \n",
       "3       2      0.0      229852  \n",
       "4       2      0.0      229852  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# includes all the information about the epoch and the model, useful for reproducibility\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "102ff488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Project Guten',\n",
       " 'he Project Gutenb',\n",
       " 'e Project Gutenbe',\n",
       " ' Project Gutenber',\n",
       " 'Project Gutenberg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the input for testing\n",
    "\n",
    "net.tensor2text(encoded[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4c9a8",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3a1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the vocabulary: 91\n",
      "Embedding dimension: 32\n",
      "Hidden units: 128\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 229,852\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The Project Gutenberg the King's side\",\n",
       " \"he Project Gutenberg the King's side \",\n",
       " \"e Project Gutenberg the King's side, \",\n",
       " \" Project Gutenberg-tm with the King's\",\n",
       " \"Project Gutenberg-tm with the King's \"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"model.arch\")\n",
    "net.load_state_dict(torch.load(\"model.pt\"))\n",
    "net.to(device)\n",
    "idx, log_probabilities = net.predict(encoded[:5], main_progress_bar = False, progress_bar = 0)\n",
    "\n",
    "net.tensor2text(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb6c7c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -9.4010, -11.3459, -11.4911, -11.7941, -12.9359],\n",
       "        [ -9.5127, -10.6926, -10.7004, -10.8122, -10.9443],\n",
       "        [-10.7119, -11.1233, -11.4759, -11.5428, -11.6310],\n",
       "        [-11.4333, -11.6359, -11.6593, -12.5754, -12.7295],\n",
       "        [-11.3023, -11.7619, -11.9283, -12.4930, -12.9769]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ab58d",
   "metadata": {},
   "source": [
    "# greedy_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02508ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the vocabulary: 91\n",
      "Embedding dimension: 32\n",
      "Hidden units: 128\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 229,852\n",
      "\n",
      "tensor([-11.8130, -12.6617, -13.5937, -15.0422, -15.8397], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg-tm the pawn at ',\n",
       " 'he Project Gutenberg-tm the pawn at K',\n",
       " 'e Project Gutenberg-tm the pawn at Kt',\n",
       " ' Project Gutenberg-tm the pawn at Kt5',\n",
       " 'Project Gutenberg-tm the pawn at Kt5.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"model.arch\")\n",
    "net.load_state_dict(torch.load(\"model.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.greedy_search(encoded[:5], progress_bar = False)\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd33c29",
   "metadata": {},
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cc754d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the vocabulary: 91\n",
      "Embedding dimension: 32\n",
      "Hidden units: 128\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 229,852\n",
      "\n",
      "tensor([-16.9294, -23.2442, -12.3178, -25.7675, -31.6309], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg-tm acteration.\\n',\n",
       " 'he Project Gutenberg-tm chances weens',\n",
       " 'e Project Gutenberg-tm exchanges on t',\n",
       " ' Project Gutenberg, and the Knagy the',\n",
       " 'Project Gutenberg Kt-B3 and rong remo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"model.arch\")\n",
    "net.load_state_dict(torch.load(\"model.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.sample(encoded[:5], progress_bar = False)\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1efbb",
   "metadata": {},
   "source": [
    "# beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04a11f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the vocabulary: 91\n",
      "Embedding dimension: 32\n",
      "Hidden units: 128\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 229,852\n",
      "\n",
      "tensor([[ -9.4010, -11.3459, -11.4911, -11.7941, -12.9359],\n",
      "        [ -9.5127, -10.6926, -10.7004, -10.8122, -10.9443],\n",
      "        [-10.7119, -11.1233, -11.4759, -11.5428, -11.6310],\n",
      "        [-11.4333, -11.6359, -11.6593, -12.5754, -12.7295],\n",
      "        [-11.3023, -11.7619, -11.9283, -12.4930, -12.9769]], device='cuda:0')\n",
      "[[\"The Project Gutenberg the King's side\",\n",
      "  'The Project Gutenberg-tm with the Kin',\n",
      "  'The Project Gutenberg-tm with the paw',\n",
      "  \"The Project Gutenberg the King's simp\",\n",
      "  'The Project Gutenberg-tm the pawns an'],\n",
      " [\"he Project Gutenberg the King's side \",\n",
      "  \"he Project Gutenberg the King's side,\",\n",
      "  \"he Project Gutenberg the King's side.\",\n",
      "  'he Project Gutenberg-tm with the King',\n",
      "  'he Project Gutenberg-tm with the pawn'],\n",
      " [\"e Project Gutenberg the King's side, \",\n",
      "  \"e Project Gutenberg the King's side. \",\n",
      "  'e Project Gutenberg-tm with the pawn ',\n",
      "  \"e Project Gutenberg-tm with the King'\",\n",
      "  \"e Project Gutenberg the King's side.\\n\"],\n",
      " [\" Project Gutenberg-tm with the King's\",\n",
      "  \" Project Gutenberg the King's side.\\n\\n\",\n",
      "  \" Project Gutenberg the King's side, a\",\n",
      "  \" Project Gutenberg the King's side. T\",\n",
      "  \" Project Gutenberg the King's side.  \"],\n",
      " [\"Project Gutenberg-tm with the King's \",\n",
      "  \"Project Gutenberg the King's side.\\n\\n \",\n",
      "  \"Project Gutenberg the King's side, an\",\n",
      "  \"Project Gutenberg the King's side. Th\",\n",
      "  \"Project Gutenberg the King's side, as\"]]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"model.arch\")\n",
    "net.load_state_dict(torch.load(\"model.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.beam_search(encoded[:5], progress_bar = False)\n",
    "\n",
    "print(log_probabilities)\n",
    "pprint([net.tensor2text(t) for t in indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4af71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
