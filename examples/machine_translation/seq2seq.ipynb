{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd486f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import seq2seq\n",
    "import re\n",
    "from nltk.lm import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1918acb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source lines 3003\n",
      "source_vocabulary 13281\n",
      "[('Schulen', ' ', 'werden', ' ', 'zu', ' ', 'gr', 'ö', 'ß', 'erem', ' ', 'Fokus', ' ', 'auf', ' ', 'Mathematik', ',', ' ', 'Rechtschreibung', ' ', 'und', ' ', 'Grammatik', ' ', 'angehalten', '\\n'), ('In', ' ', 'Kursen', ' ', 'zu', ' ', 'englischer', ' ', 'Literatur', ' ', 'm', 'ü', 'ssen', ' ', 'Sch', 'ü', 'ler', ' ', 'k', 'ü', 'nftig', ' ', 'mindestens', ' ', 'ein', ' ', 'St', 'ü', 'ck', ' ', 'von', ' ', 'Shakespeare', ',', ' ', 'einen', ' ', 'Roman', ' ', 'des', ' ', '1', '9', '.', ' ', 'Jahrhunderts', ',', ' ', 'romantische', ' ', 'Lyrik', ' ', 'und', ' ', 'zeitgen', 'ö', 'ssische', ' ', 'britische', ' ', 'Romane', ' ', 'ab', ' ', '1', '9', '1', '4', ' ', 'behandeln', '.', '\\n'), ('In', ' ', 'die', ' ', 'Pr', 'ü', 'fung', ' ', 'finden', ' ', 'auch', ' ', '„', 'ungesehene', ' ', 'Texte', '\"', ' ', 'Eingang', ',', ' ', 'um', ' ', 'zu', ' ', 'breiterem', ' ', 'Lesen', ' ', 'anzuregen', '.', '\\n'), ('Der', ' ', 'kombinierte', ' ', 'Kurs', ' ', 'aus', ' ', 'englischer', ' ', 'Literatur', ' ', 'und', ' ', 'Sprache', ' ', 'wird', ' ', 'abgeschafft', '.', '\\n'), ('Ab', ' ', '2', '0', '1', '5', ' ', 'm', 'ü', 'ssen', ' ', 'Sch', 'ü', 'ler', ' ', 'eine', ' ', 'eigenst', 'ä', 'ndige', ' ', 'GCSE', '-', 'Pr', 'ü', 'fung', ' ', 'f', 'ü', 'r', ' ', 'Sprache', ' ', 'ablegen', ',', ' ', 'wobei', ' ', 'es', ' ', 'starke', ' ', 'Anreize', ' ', 'daf', 'ü', 'r', ' ', 'gibt', ',', ' ', 'englische', ' ', 'Literatur', ' ', 'als', ' ', 'separate', ' ', 'Qualifikation', ' ', 'zu', ' ', 'w', 'ä', 'hlen', '.', '\\n')]\n"
     ]
    }
   ],
   "source": [
    "# source\n",
    "\n",
    "with open(\"wmt14-de-en.src\", encoding = \"utf-8\") as file:\n",
    "    source = file.readlines()\n",
    "print(\"source lines\", len(source))\n",
    "\n",
    "source_tokens = [re.findall(r\"[a-zA-Z]+|[^a-zA-Z]\", text) for text in source]\n",
    "\n",
    "source_vocabulary = Vocabulary(sum(source_tokens, start = []))\n",
    "print(\"source_vocabulary\", len(source_vocabulary))\n",
    "\n",
    "source_tokens = [source_vocabulary.lookup(l) for l in source_tokens]\n",
    "\n",
    "print(source_tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f9b874",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target lines 3003\n",
      "target_vocabulary 9943\n",
      "3003\n",
      "[('Schools', ' ', 'urged', ' ', 'to', ' ', 'focus', ' ', 'more', ' ', 'on', ' ', 'maths', ',', ' ', 'spelling', ' ', 'and', ' ', 'grammar', '\\n'), ('English', ' ', 'literature', ' ', 'courses', ' ', 'will', ' ', 'require', ' ', 'pupils', ' ', 'to', ' ', 'study', ' ', 'at', ' ', 'least', ' ', 'one', ' ', 'Shakespeare', ' ', 'play', ',', ' ', 'a', ' ', '1', '9', 'th', ' ', 'century', ' ', 'novel', ',', ' ', 'Romantic', ' ', 'poetry', ' ', 'and', ' ', 'contemporary', ' ', 'British', ' ', 'fiction', ' ', 'from', ' ', '1', '9', '1', '4', ' ', 'onwards', '.', '\\n'), ('The', ' ', 'exam', ' ', 'will', ' ', 'also', ' ', 'feature', ' ', '\"', 'unseen', ' ', 'texts', '\"', ' ', 'to', ' ', 'encourage', ' ', 'wider', ' ', 'reading', ';', '\\n'), ('A', ' ', 'combined', ' ', 'English', ' ', 'literature', ' ', 'and', ' ', 'language', ' ', 'course', ' ', 'will', ' ', 'be', ' ', 'scrapped', '.', '\\n'), ('From', ' ', '2', '0', '1', '5', ',', ' ', 'pupils', ' ', 'will', ' ', 'be', ' ', 'required', ' ', 'to', ' ', 'take', ' ', 'a', ' ', 'standalone', ' ', 'GCSE', ' ', 'in', ' ', 'language', ',', ' ', 'with', ' ', 'strong', ' ', 'incentives', ' ', 'to', ' ', 'choose', ' ', 'English', ' ', 'literature', ' ', 'as', ' ', 'a', ' ', 'separate', ' ', 'qualification', '.', '\\n')]\n"
     ]
    }
   ],
   "source": [
    "# target\n",
    "\n",
    "with open(\"wmt14-de-en.ref\", encoding = \"utf-8\") as file:\n",
    "    target = file.readlines()\n",
    "print(\"target lines\", len(target))\n",
    "\n",
    "target_tokens = [re.findall(r\"[a-zA-Z]+|[^a-zA-Z]\", text) for text in target]\n",
    "\n",
    "\n",
    "target_vocabulary = Vocabulary(sum(target_tokens, start = []))\n",
    "print(\"target_vocabulary\", len(target_vocabulary))\n",
    "\n",
    "target_tokens = [target_vocabulary.lookup(l) for l in target_tokens]\n",
    "print(len(target_tokens))\n",
    "\n",
    "print(target_tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "febf01fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ba8286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Transformer\n",
      "Tokens in the input vocabulary: 13,281\n",
      "Tokens in the output vocabulary: 9,943\n",
      "Max sequence length: 170\n",
      "Embedding dimension: 128\n",
      "Feedforward dimension: 512\n",
      "Encoder layers: 2\n",
      "Decoder layers: 2\n",
      "Attention heads: 8\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 5,204,442\n",
      "\n",
      "source torch.Size([3003, 157])\n",
      "target torch.Size([3003, 161])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a851e5168aee477dabc098ea7ced6dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Epochs: 20\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0\n",
      "Epoch | Train                 | Minutes\n",
      "      | Loss     | Error Rate |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441ffb6460604546a27074a30e2a7afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 |   5.2672 |     88.074 |     0.7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bfef9678694030bc8cf9c4d4afb299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 |   3.8758 |     86.236 |     1.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1edab23bb241baadf6c5c990f7eecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3 |   3.6879 |     86.162 |     2.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7425fcd129446a8d7fca634cfbee24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 |   3.6073 |     86.107 |     2.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8556b116208944df9a0fa4d08014ce28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 |   3.5505 |     86.043 |     3.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396591dab9594b018428f8dbc0755684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6 |   3.5122 |     85.993 |     4.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866ea17bf8184240892f08fa123e42b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7 |   3.4703 |     85.939 |     5.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292035f6b78c46138d8ecc051a442155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8 |   3.4305 |     85.867 |     5.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdb92ed6ef64e48940f8e8278a5aabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9 |   3.3868 |     85.813 |     6.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6ec1dd42d8488582f842a06baab4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 |   3.3409 |     85.732 |     7.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3ac73d05df4372b1812e7cf32d7b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 |   3.2968 |     85.657 |     8.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bb53bb2ef044429522b2efa51469f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 |   3.2518 |     85.586 |     9.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56dc516e222412ca9d912e5e30bec11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 |   3.2001 |     85.491 |     9.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b563a1c39340caabf5b0781abe17ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 |   3.1494 |     85.406 |    10.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9791c61b4ab648c599681e0776f6123a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 |   3.0971 |     85.309 |    11.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dc354beec440ecb90a9c8b7751e5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 |   3.0425 |     85.220 |    12.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e461e303ef4402299144c983a6bf6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 |   2.9886 |     85.113 |    12.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b7f3cee8234c3a8d83ab762fdc2906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 |   2.9320 |     84.999 |    13.7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a06127682b444e9a68d22cb16a7788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 |   2.8740 |     84.889 |    14.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef75f0a53f54550af3ff693a8d07ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 |   2.8162 |     84.781 |    15.2\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(seq2seq)  \n",
    "\n",
    "# net = seq2seq.LSTM(source_vocabulary, target_vocabulary)\n",
    "net = seq2seq.Transformer(source_vocabulary, target_vocabulary, max_sequence_length = 170, embedding_dimension = 128, feedforward_dimension=512, attention_heads = 8)\n",
    "net.to(device)\n",
    "\n",
    "source_tensor = net.text2tensor(source_tokens)\n",
    "print(\"source\", source_tensor.shape)\n",
    "\n",
    "target_tensor = net.text2tensor(target_tokens, vocabulary = net.out2i)\n",
    "print(\"target\", target_tensor.shape)\n",
    "\n",
    "performance = net.fit(source_tensor, target_tensor, save_path = \"model.pt\", batch_size = 10, epochs = 20)\n",
    "net.save_architecture(\"model.arch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d818646c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_error_rate</th>\n",
       "      <th>training_minutes</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>model</th>\n",
       "      <th>max_sequence_length</th>\n",
       "      <th>embedding_dimension</th>\n",
       "      <th>feedforward_dimension</th>\n",
       "      <th>encoder_layers</th>\n",
       "      <th>decoder_layers</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.267163</td>\n",
       "      <td>88.074426</td>\n",
       "      <td>0.735744</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.875790</td>\n",
       "      <td>86.236472</td>\n",
       "      <td>1.453770</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.687935</td>\n",
       "      <td>86.161547</td>\n",
       "      <td>2.162948</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.607276</td>\n",
       "      <td>86.106602</td>\n",
       "      <td>2.875041</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.550507</td>\n",
       "      <td>86.043332</td>\n",
       "      <td>3.587308</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3.512205</td>\n",
       "      <td>85.992549</td>\n",
       "      <td>4.321624</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>3.470341</td>\n",
       "      <td>85.939477</td>\n",
       "      <td>5.089064</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3.430460</td>\n",
       "      <td>85.867466</td>\n",
       "      <td>5.866780</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3.386772</td>\n",
       "      <td>85.813353</td>\n",
       "      <td>6.643522</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3.340865</td>\n",
       "      <td>85.731768</td>\n",
       "      <td>7.422444</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>3.296755</td>\n",
       "      <td>85.656635</td>\n",
       "      <td>8.201767</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>3.251802</td>\n",
       "      <td>85.585664</td>\n",
       "      <td>8.980039</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>3.200149</td>\n",
       "      <td>85.490759</td>\n",
       "      <td>9.757189</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3.149439</td>\n",
       "      <td>85.405844</td>\n",
       "      <td>10.535237</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>3.097055</td>\n",
       "      <td>85.308858</td>\n",
       "      <td>11.313046</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>3.042513</td>\n",
       "      <td>85.219780</td>\n",
       "      <td>12.090748</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2.988569</td>\n",
       "      <td>85.113012</td>\n",
       "      <td>12.871889</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2.931968</td>\n",
       "      <td>84.998959</td>\n",
       "      <td>13.655960</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2.874021</td>\n",
       "      <td>84.889486</td>\n",
       "      <td>14.437710</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2.816206</td>\n",
       "      <td>84.780844</td>\n",
       "      <td>15.224385</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>170</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5204442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_error_rate  training_minutes  learning_rate  \\\n",
       "0       1    5.267163         88.074426          0.735744         0.0001   \n",
       "1       2    3.875790         86.236472          1.453770         0.0001   \n",
       "2       3    3.687935         86.161547          2.162948         0.0001   \n",
       "3       4    3.607276         86.106602          2.875041         0.0001   \n",
       "4       5    3.550507         86.043332          3.587308         0.0001   \n",
       "5       6    3.512205         85.992549          4.321624         0.0001   \n",
       "6       7    3.470341         85.939477          5.089064         0.0001   \n",
       "7       8    3.430460         85.867466          5.866780         0.0001   \n",
       "8       9    3.386772         85.813353          6.643522         0.0001   \n",
       "9      10    3.340865         85.731768          7.422444         0.0001   \n",
       "10     11    3.296755         85.656635          8.201767         0.0001   \n",
       "11     12    3.251802         85.585664          8.980039         0.0001   \n",
       "12     13    3.200149         85.490759          9.757189         0.0001   \n",
       "13     14    3.149439         85.405844         10.535237         0.0001   \n",
       "14     15    3.097055         85.308858         11.313046         0.0001   \n",
       "15     16    3.042513         85.219780         12.090748         0.0001   \n",
       "16     17    2.988569         85.113012         12.871889         0.0001   \n",
       "17     18    2.931968         84.998959         13.655960         0.0001   \n",
       "18     19    2.874021         84.889486         14.437710         0.0001   \n",
       "19     20    2.816206         84.780844         15.224385         0.0001   \n",
       "\n",
       "    weight_decay        model  max_sequence_length  embedding_dimension  \\\n",
       "0              0  Transformer                  170                  128   \n",
       "1              0  Transformer                  170                  128   \n",
       "2              0  Transformer                  170                  128   \n",
       "3              0  Transformer                  170                  128   \n",
       "4              0  Transformer                  170                  128   \n",
       "5              0  Transformer                  170                  128   \n",
       "6              0  Transformer                  170                  128   \n",
       "7              0  Transformer                  170                  128   \n",
       "8              0  Transformer                  170                  128   \n",
       "9              0  Transformer                  170                  128   \n",
       "10             0  Transformer                  170                  128   \n",
       "11             0  Transformer                  170                  128   \n",
       "12             0  Transformer                  170                  128   \n",
       "13             0  Transformer                  170                  128   \n",
       "14             0  Transformer                  170                  128   \n",
       "15             0  Transformer                  170                  128   \n",
       "16             0  Transformer                  170                  128   \n",
       "17             0  Transformer                  170                  128   \n",
       "18             0  Transformer                  170                  128   \n",
       "19             0  Transformer                  170                  128   \n",
       "\n",
       "    feedforward_dimension  encoder_layers  decoder_layers  attention_heads  \\\n",
       "0                     512               2               2                8   \n",
       "1                     512               2               2                8   \n",
       "2                     512               2               2                8   \n",
       "3                     512               2               2                8   \n",
       "4                     512               2               2                8   \n",
       "5                     512               2               2                8   \n",
       "6                     512               2               2                8   \n",
       "7                     512               2               2                8   \n",
       "8                     512               2               2                8   \n",
       "9                     512               2               2                8   \n",
       "10                    512               2               2                8   \n",
       "11                    512               2               2                8   \n",
       "12                    512               2               2                8   \n",
       "13                    512               2               2                8   \n",
       "14                    512               2               2                8   \n",
       "15                    512               2               2                8   \n",
       "16                    512               2               2                8   \n",
       "17                    512               2               2                8   \n",
       "18                    512               2               2                8   \n",
       "19                    512               2               2                8   \n",
       "\n",
       "   activation  dropout  parameters  \n",
       "0        relu      0.0     5204442  \n",
       "1        relu      0.0     5204442  \n",
       "2        relu      0.0     5204442  \n",
       "3        relu      0.0     5204442  \n",
       "4        relu      0.0     5204442  \n",
       "5        relu      0.0     5204442  \n",
       "6        relu      0.0     5204442  \n",
       "7        relu      0.0     5204442  \n",
       "8        relu      0.0     5204442  \n",
       "9        relu      0.0     5204442  \n",
       "10       relu      0.0     5204442  \n",
       "11       relu      0.0     5204442  \n",
       "12       relu      0.0     5204442  \n",
       "13       relu      0.0     5204442  \n",
       "14       relu      0.0     5204442  \n",
       "15       relu      0.0     5204442  \n",
       "16       relu      0.0     5204442  \n",
       "17       relu      0.0     5204442  \n",
       "18       relu      0.0     5204442  \n",
       "19       relu      0.0     5204442  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# includes all the information about the epoch and the model, useful for reproducibility\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a99b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>Schulen werden zu größerem Fokus auf Mathematik, Rechtschreibung und Grammatik angehalten\\n<END>',\n",
       " '<START>In Kursen zu englischer Literatur müssen Schüler künftig mindestens ein Stück von Shakespeare, einen Roman des 19. Jahrhunderts, romantische Lyrik und zeitgenössische britische Romane ab 1914 behandeln.\\n<END>',\n",
       " '<START>In die Prüfung finden auch „ungesehene Texte\" Eingang, um zu breiterem Lesen anzuregen.\\n<END>',\n",
       " '<START>Der kombinierte Kurs aus englischer Literatur und Sprache wird abgeschafft.\\n<END>',\n",
       " '<START>Ab 2015 müssen Schüler eine eigenständige GCSE-Prüfung für Sprache ablegen, wobei es starke Anreize dafür gibt, englische Literatur als separate Qualifikation zu wählen.\\n<END>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the input for testing\n",
    "\n",
    "net.tensor2text(source_tensor[:5], vocabulary = net.i2in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da8a06",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b8c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Transformer\n",
      "Tokens in the input vocabulary: 13,281\n",
      "Tokens in the output vocabulary: 9,943\n",
      "Max sequence length: 170\n",
      "Embedding dimension: 128\n",
      "Feedforward dimension: 512\n",
      "Encoder layers: 2\n",
      "Decoder layers: 2\n",
      "Attention heads: 8\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 5,204,442\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<START>The \\n<END>',\n",
       " '<START>In addition, 2, the 19770 and to the 170 and 1977777777777770 and to 10 a and the of 177.\\n<END>',\n",
       " '<START>Mr said: \" said to \\n<END>',\n",
       " '<START>The firefighters is is and be be to the \\n<END>',\n",
       " '<START>In 2001, the case of the town of the 10150012001501, to to a of to of to the of a <END>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.load_architecture(\"model.arch\")\n",
    "net.load_state_dict(torch.load(\"model.pt\"))\n",
    "net.to(device)\n",
    "\n",
    "idx, log_probabilities = net.predict(source_tensor[:5], main_progress_bar = False, progress_bar = 0)\n",
    "\n",
    "net.tensor2text(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a79e9",
   "metadata": {},
   "source": [
    "# greedy_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47bec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Transformer\n",
      "Tokens in the input vocabulary: 13,281\n",
      "Tokens in the output vocabulary: 9,943\n",
      "Max sequence length: 170\n",
      "Embedding dimension: 128\n",
      "Feedforward dimension: 512\n",
      "Encoder layers: 2\n",
      "Decoder layers: 2\n",
      "Attention heads: 8\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 5,204,442\n",
      "\n",
      "tensor([-29.2347, -34.9740, -28.5281, -32.5123, -28.4796], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<START>The \\n<END>',\n",
       " '<START>The 19-year-old of the 19 of a ',\n",
       " '<START>He said the \"The to \\n<END>',\n",
       " '<START>The firefighters is and be a team of the tournament ',\n",
       " '<START>The 2010, is in the country of the ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.load_architecture(\"model.arch\")\n",
    "net.load_state_dict(torch.load(\"model.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.greedy_search(source_tensor[:5], progress_bar = False)\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e31f5",
   "metadata": {},
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479cef0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Transformer\n",
      "Tokens in the input vocabulary: 13,281\n",
      "Tokens in the output vocabulary: 9,943\n",
      "Max sequence length: 170\n",
      "Embedding dimension: 128\n",
      "Feedforward dimension: 512\n",
      "Encoder layers: 2\n",
      "Decoder layers: 2\n",
      "Attention heads: 8\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 5,204,442\n",
      "\n",
      "tensor([-79.1392, -84.9124, -81.9127, -63.3095, -59.9535], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<START>The Winter meet Boeing and drawn nurseries it its-Hare ',\n",
       " '<START>Two half groundwater9987-every-outlets is laws some ',\n",
       " '<START>Uli day \"head she first with took The declare from',\n",
       " '<START>The friendly waits and released Treubel own week and deeper ',\n",
       " '<START>One Health said Asia only Thursday in been a Vegetarian ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.load_architecture(\"model.arch\")\n",
    "net.load_state_dict(torch.load(\"model.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.sample(source_tensor[:5], progress_bar = False)\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2546fd13",
   "metadata": {},
   "source": [
    "# beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89c041e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Transformer\n",
      "Tokens in the input vocabulary: 13,281\n",
      "Tokens in the output vocabulary: 9,943\n",
      "Max sequence length: 170\n",
      "Embedding dimension: 128\n",
      "Feedforward dimension: 512\n",
      "Encoder layers: 2\n",
      "Decoder layers: 2\n",
      "Attention heads: 8\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 5,204,442\n",
      "\n",
      "tensor([[-29.0091, -29.7633, -29.9004, -30.0021, -30.2870],\n",
      "        [-29.7181, -29.8997, -30.2440, -32.3113, -32.3713],\n",
      "        [-23.7280, -24.6271, -25.4958, -25.5079, -25.5574],\n",
      "        [-28.5049, -28.6433, -28.6560, -28.8708, -29.2933],\n",
      "        [-30.2971, -30.6782, -31.4014, -31.4419, -31.4628]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['<START>The \\n<END>',\n",
       "  '<START>The \\n<END>',\n",
       "  '<START>The \\n<END>',\n",
       "  '<START>The \\n<END>',\n",
       "  '<START>The \\n<END>'],\n",
       " ['<START>In addition, 2, the 19770 of the ',\n",
       "  '<START>In addition, 2, the 19770 of a ',\n",
       "  '<START>In addition, 2, the 19770 and to ',\n",
       "  '<START>In addition, 2, the 1977 and to the',\n",
       "  '<START>In addition, 2, the 1977 and to 1'],\n",
       " ['<START>Mr said: \" said to \\n<END>',\n",
       "  '<START>Mr said: \" said to \\n<END>',\n",
       "  '<START>Mr said: \" said to \\n<END>',\n",
       "  '<START>Mr said: \" said to \\n<END>',\n",
       "  '<START>Mr said: \" said to \\n<END>'],\n",
       " ['<START>The firefighters is is and be of the of and ',\n",
       "  '<START>The firefighters is is and be be to the of ',\n",
       "  '<START>The firefighters is is and be be to the \\n<END>',\n",
       "  '<START>The firefighters is is and be be to the and ',\n",
       "  '<START>The firefighters is is and be be to the tournament '],\n",
       " ['<START>In 2001, the case of the town of ',\n",
       "  '<START>In 2012, the was of the town of ',\n",
       "  '<START>In 2012, the was of the of the ',\n",
       "  '<START>In 2001, the case of the of the ',\n",
       "  '<START>In 2001, the case of the town to ']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(seq2seq)    \n",
    "net = seq2seq.load_architecture(\"model.arch\")\n",
    "net.load_state_dict(torch.load(\"model.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.beam_search(source_tensor[:5], progress_bar = 0)\n",
    "\n",
    "print(log_probabilities)\n",
    "[net.tensor2text(t) for t in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81942d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9788f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
