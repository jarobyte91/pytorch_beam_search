{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164047"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"alice.txt\") as file:\n",
    "    text = file.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg eBook of Alice’s Adventures in Wonderland, by Lewis Carroll\\n\\nThis eBook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this eBook or online at\\nwww.gutenberg.org. If you are not located in the United States, you\\nwill have to check the laws of the country where you are located before\\nusing this eBook.\\n\\nTitle: Alice’s Adventures in Wonderland\\n\\nAuthor: Lewis Carroll\\n\\nRelease Date: January, 1991 [eBook #11]\\n[Most recently updated: October 12, 2020]\\n\\nLanguage: English\\n\\nCharacter set encoding: UTF-8\\n\\nProduced by: Arthur DiBianca and David Widger\\n\\n*** START OF THE PROJECT GUTENBERG EBOOK ALICE’S ADVENTURES IN WONDERLAND ***\\n\\n[Illustration]\\n\\n\\n\\n\\nAlice’s Adventures in Wonderland\\n\\nby Lewis Carroll\\n\\nTHE MILLENNIUM FULCRUM EDITION 3.0\\n\\nContents\\n\\n CHAPTER I.     Down the Rabbit-Hole\\n CHAPTER II.    The Pool of Tears\\n CHAPTER III.   A Caucus-Race and a Long Tale\\n CHAPTER IV.    The Rabbit Sends in a Little Bill\\n CHAPTER V.     Advice from a Caterpillar\\n CHAPTER VI.    Pig and Pepper\\n CHAPTER VII.   A Mad Tea-Party\\n CHAPTER VIII.  The Queen’s Croquet-Ground\\n CHAPTER IX.    The Mock Turtle’s Story\\n CHAPTER X.     The Lobster Quadrille\\n CHAPTER XI.    Who Stole the Tarts?\\n CHAPTER XII.   Alice’s Evidence\\n\\n\\n\\n\\nCHAPTER I.\\nDown the Rabbit-Hole\\n\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister was reading, but it had no pictures or\\nconversations in it, “and what is the use of a book,” thought Alice\\n“without pictures or conversations?”\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\nmaking a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so _very_ remarkable in that; nor did Alice think it\\nso _very_ much out of the way to hear the Rabbit say to itself, “Oh\\ndear! Oh dear! I shall be late!” (when she thought it over afterwards,\\nit occurred to her that she ought to have wondered at this, but at the\\ntime it all seemed quite natural); but when the Rabbit actually _took a\\nwatch out of its waistcoat-pocket_, and looked at it, and then hurried\\non, Alice started to her feet, for it flashed across her mind that she\\nhad never before seen a rabbit with either a waistcoat-pocket, or a\\nwatch to take out of it, and burning with curiosity, she ran across the\\nfield after it, and fortunately was just in time to see it pop down a\\nlarge rabbit-hole under the hedge.\\n\\nIn another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\\n\\nEither the well was very deep, or she fell very slowly, for she had\\nplenty of time as she went down to look about her and to wonder what\\nwas going to happen next. First, she tried to look down and make out\\nwhat she was coming to, but it was too dark to see anything; then she\\nlooked at the sides of the well, and noticed that they were filled with\\ncupboards and book-shelves; here and there she saw maps and pictures\\nhung upon pegs. She took down a jar from one of the shelves as she\\npassed; it was labelled “ORANGE MARMALADE”, but to her great\\ndisappointment it was empty: she did not like to drop the jar for fear\\nof killing somebody underneath, so managed to put it into one of the\\ncupboards as she fell past it.\\n\\n“Well!” thought Alice to herself, “after such a fall as this, I shall\\nthink nothing of tumbling down stairs! How brave they’ll all think me\\nat home! Why, I wouldn’t say anything about it, even if I fell off the\\ntop of the house!” (Which was very likely true.)\\n\\nDown, down, down. Would the fall _never_ come to an end? “I wonder how\\nmany miles I’ve fallen by this time?” she said aloud. “I must be\\ngetting somewhere near the centre of the earth. Let me see: that would\\nbe four thousand miles down, I think—” (for, you see, Alice had learnt\\nseveral things of this sort in her lessons in the schoolroom, and\\nthough this was not a _very_ good opportunity for showing off her\\nknowledge, as there was no one to listen to her, still it was good\\npractice to say it over) “—yes, that’s about the right distance—but\\nthen I wonder what Latitude or Longitude I’ve got to?” (Alice had no\\nidea what Latitude was, or Longitude either, but thought they were nice\\ngrand words to say.)\\n\\nPresently she began again. “I wonder if I shall fall right _through_\\nthe earth! How funny it’ll seem to come out among the people that walk\\nwith their heads downward! The Antipa'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " ' ',\n",
       " 'project',\n",
       " ' ',\n",
       " 'gutenberg',\n",
       " ' ',\n",
       " 'ebook',\n",
       " ' ',\n",
       " 'of',\n",
       " ' ',\n",
       " 'alice',\n",
       " '’',\n",
       " 's',\n",
       " ' ',\n",
       " 'adventures',\n",
       " ' ',\n",
       " 'in',\n",
       " ' ',\n",
       " 'wonderland',\n",
       " ',',\n",
       " ' ',\n",
       " 'by',\n",
       " ' ',\n",
       " 'lewis',\n",
       " ' ',\n",
       " 'carroll',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'this',\n",
       " ' ',\n",
       " 'ebook',\n",
       " ' ',\n",
       " 'is',\n",
       " ' ',\n",
       " 'for',\n",
       " ' ',\n",
       " 'the',\n",
       " ' ',\n",
       " 'use',\n",
       " ' ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = re.findall(r\"[a-zA-Z]+|[^a-zA-Z]\", text.lower())[1:]\n",
    "# tokens = re.findall(r\"[a-zA-Z]+|[^a-zA-Z\\s]\", text)[1:]\n",
    "print(len(tokens))\n",
    "tokens[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' ', 27431),\n",
       " ('\\n', 3761),\n",
       " (',', 2571),\n",
       " ('the', 1839),\n",
       " ('.', 1222),\n",
       " ('“', 1118),\n",
       " ('”', 1114),\n",
       " ('and', 942),\n",
       " ('to', 811),\n",
       " ('’', 710),\n",
       " ('a', 695),\n",
       " ('of', 638),\n",
       " ('it', 610),\n",
       " ('she', 553),\n",
       " ('i', 546),\n",
       " ('you', 486),\n",
       " ('said', 462),\n",
       " ('!', 452),\n",
       " ('_', 440),\n",
       " ('in', 435)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = Counter(tokens)\n",
    "print(len(vocabulary))\n",
    "vocabulary.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2i = {w:i for i, w in enumerate(sorted(vocabulary))}\n",
    "i2word = {w:i for w, i in enumerate(sorted(vocabulary))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bab8cafac624b9284acb6fb342f700b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=70984.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([70984, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = 20\n",
    "\n",
    "X = []\n",
    "for i in tqdm(range(len(tokens) - steps)):\n",
    "    X.append([word2i[w] for w in tokens[i:i + steps]])\n",
    "    \n",
    "X = torch.tensor(X, device = device)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive LSTM\n",
      "Tokens in the in vocabulary: 3,043\n",
      "Tokens in the out vocabulary: 3,043\n",
      "Embedding dimension: 32\n",
      "Hidden units: 128\n",
      "Layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 704,963\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acf52dbb9ee4edf992f035b23babbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | Train                 | Minutes\n",
      "      | Loss     | Error Rate |\n",
      "---------------------------------------\n",
      "    1 |   3.7176 |     59.619 |     0.3\n",
      "    2 |   3.1794 |     56.612 |     0.7\n",
      "    3 |   2.9368 |     54.685 |     1.0\n",
      "    4 |   2.7088 |     52.025 |     1.4\n",
      "    5 |   2.5320 |     50.409 |     1.7\n",
      "    6 |   2.3827 |     49.011 |     2.0\n",
      "    7 |   2.2485 |     47.656 |     2.4\n",
      "    8 |   2.1242 |     46.372 |     2.7\n",
      "    9 |   2.0041 |     44.998 |     3.1\n",
      "   10 |   1.8862 |     43.501 |     3.4\n",
      "   11 |   1.7708 |     41.839 |     3.7\n",
      "   12 |   1.6608 |     40.108 |     4.1\n",
      "   13 |   1.5571 |     38.269 |     4.4\n",
      "   14 |   1.4631 |     36.561 |     4.8\n",
      "   15 |   1.3768 |     34.865 |     5.1\n",
      "   16 |   1.2975 |     33.228 |     5.4\n",
      "   17 |   1.2241 |     31.702 |     5.8\n",
      "   18 |   1.1574 |     30.236 |     6.1\n",
      "   19 |   1.0964 |     28.849 |     6.4\n",
      "   20 |   1.0411 |     27.587 |     6.8\n",
      "   21 |   0.9908 |     26.451 |     7.1\n",
      "   22 |   0.9448 |     25.386 |     7.5\n",
      "   23 |   0.9037 |     24.412 |     7.8\n",
      "   24 |   0.8656 |     23.498 |     8.1\n",
      "   25 |   0.8319 |     22.707 |     8.5\n",
      "   26 |   0.8006 |     21.952 |     8.8\n",
      "   27 |   0.7720 |     21.230 |     9.2\n",
      "   28 |   0.7469 |     20.670 |     9.5\n",
      "   29 |   0.7236 |     20.122 |     9.8\n",
      "   30 |   0.7029 |     19.660 |    10.2\n",
      "   31 |   0.6842 |     19.248 |    10.5\n",
      "   32 |   0.6668 |     18.850 |    10.9\n",
      "   33 |   0.6512 |     18.508 |    11.2\n",
      "   34 |   0.6371 |     18.195 |    11.5\n",
      "   35 |   0.6244 |     17.955 |    11.9\n",
      "   36 |   0.6126 |     17.701 |    12.2\n",
      "   37 |   0.6021 |     17.522 |    12.6\n",
      "   38 |   0.5926 |     17.337 |    12.9\n",
      "   39 |   0.5837 |     17.169 |    13.2\n",
      "   40 |   0.5754 |     17.019 |    13.6\n",
      "   41 |   0.5682 |     16.888 |    13.9\n",
      "   42 |   0.5612 |     16.769 |    14.3\n",
      "   43 |   0.5546 |     16.676 |    14.6\n",
      "   44 |   0.5486 |     16.554 |    14.9\n",
      "   45 |   0.5429 |     16.473 |    15.3\n",
      "   46 |   0.5381 |     16.388 |    15.6\n",
      "   47 |   0.5332 |     16.302 |    16.0\n",
      "   48 |   0.5288 |     16.227 |    16.3\n",
      "   49 |   0.5247 |     16.174 |    16.6\n",
      "   50 |   0.5206 |     16.101 |    17.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = autoregressive.LSTM(word2i, i2word)\n",
    "model_1.to(device)\n",
    "\n",
    "log = model_1.fit(X, epochs = 50, progress_bar = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of alice’s adventures in wonderland,']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.tensor2text(X[:1], separator = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97e785da705406884f032e4ee6f77b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54c94591c4e4a95aa71dbc995a17b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=199.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "torch.Size([1, 220])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of alice’s adventures in wonderland, by lewis carroll. it was all ridges and furrows; the balls were live at last, and managed to swallow a morsel of the sea, “and in that case i can go back by the whole thing, and longed to change the subject.” she said aloud. “i must be shutting up like a telescope! i think i could, if i only knew it was a little door about fifteen inches high: she tried the middle of her favourite word ‘moral,’ and the arm that was in the middle of her favourite word ‘']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_1, probs_1 = model_1.predict(X[:1], max_predictions = 200, method = \"beam_search\")\n",
    "\n",
    "print(idx_1.shape)\n",
    "\n",
    "model_1.tensor2text(idx_1, separator = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
