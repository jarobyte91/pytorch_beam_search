{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f17b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import importlib\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac5737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91783cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164047"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"alice.txt\") as file:\n",
    "    text = file.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740d826c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg eBook of Alice’s Adventures in Wonderland, by Lewis Carroll\\n\\nThis eBook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this eBook or online at\\nwww.gutenberg.org. If you are not located in the United States, you\\nwill have to check the laws of the country where you are located before\\nusing this eBook.\\n\\nTitle: Alice’s Adventures in Wonderland\\n\\nAuthor: Lewis Carroll\\n\\nRelease Date: January, 1991 [eBook #11]\\n[Most recently updated: October 12, 2020]\\n\\nLanguage: English\\n\\nCharacter set encoding: UTF-8\\n\\nProduced by: Arthur DiBianca and David Widger\\n\\n*** START OF THE PROJECT GUTENBERG EBOOK ALICE’S ADVENTURES IN WONDERLAND ***\\n\\n[Illustration]\\n\\n\\n\\n\\nAlice’s Adventures in Wonderland\\n\\nby Lewis Carroll\\n\\nTHE MILLENNIUM FULCRUM EDITION 3.0\\n\\nContents\\n\\n CHAPTER I.     Down the Rabbit-Hole\\n CHAPTER II.    The Pool of Tears\\n CHAPTER III.   A Caucus-Race and a Long Tale\\n CHAPTER IV.    The Rabbit Sends in a Little Bill\\n CHAPTER V.     Advice from a Caterpillar\\n CHAPTER VI.    Pig and Pepper\\n CHAPTER VII.   A Mad Tea-Party\\n CHAPTER VIII.  The Queen’s Croquet-Ground\\n CHAPTER IX.    The Mock Turtle’s Story\\n CHAPTER X.     The Lobster Quadrille\\n CHAPTER XI.    Who Stole the Tarts?\\n CHAPTER XII.   Alice’s Evidence\\n\\n\\n\\n\\nCHAPTER I.\\nDown the Rabbit-Hole\\n\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister was reading, but it had no pictures or\\nconversations in it, “and what is the use of a book,” thought Alice\\n“without pictures or conversations?”\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\nmaking a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so _very_ remarkable in that; nor did Alice think it\\nso _very_ much out of the way to hear the Rabbit say to itself, “Oh\\ndear! Oh dear! I shall be late!” (when she thought it over afterwards,\\nit occurred to her that she ought to have wondered at this, but at the\\ntime it all seemed quite natural); but when the Rabbit actually _took a\\nwatch out of its waistcoat-pocket_, and looked at it, and then hurried\\non, Alice started to her feet, for it flashed across her mind that she\\nhad never before seen a rabbit with either a waistcoat-pocket, or a\\nwatch to take out of it, and burning with curiosity, she ran across the\\nfield after it, and fortunately was just in time to see it pop down a\\nlarge rabbit-hole under the hedge.\\n\\nIn another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\\n\\nEither the well was very deep, or she fell very slowly, for she had\\nplenty of time as she went down to look about her and to wonder what\\nwas going to happen next. First, she tried to look down and make out\\nwhat she was coming to, but it was too dark to see anything; then she\\nlooked at the sides of the well, and noticed that they were filled with\\ncupboards and book-shelves; here and there she saw maps and pictures\\nhung upon pegs. She took down a jar from one of the shelves as she\\npassed; it was labelled “ORANGE MARMALADE”, but to her great\\ndisappointment it was empty: she did not like to drop the jar for fear\\nof killing somebody underneath, so managed to put it into one of the\\ncupboards as she fell past it.\\n\\n“Well!” thought Alice to herself, “after such a fall as this, I shall\\nthink nothing of tumbling down stairs! How brave they’ll all think me\\nat home! Why, I wouldn’t say anything about it, even if I fell off the\\ntop of the house!” (Which was very likely true.)\\n\\nDown, down, down. Would the fall _never_ come to an end? “I wonder how\\nmany miles I’ve fallen by this time?” she said aloud. “I must be\\ngetting somewhere near the centre of the earth. Let me see: that would\\nbe four thousand miles down, I think—” (for, you see, Alice had learnt\\nseveral things of this sort in her lessons in the schoolroom, and\\nthough this was not a _very_ good opportunity for showing off her\\nknowledge, as there was no one to listen to her, still it was good\\npractice to say it over) “—yes, that’s about the right distance—but\\nthen I wonder what Latitude or Longitude I’ve got to?” (Alice had no\\nidea what Latitude was, or Longitude either, but thought they were nice\\ngrand words to say.)\\n\\nPresently she began again. “I wonder if I shall fall right _through_\\nthe earth! How funny it’ll seem to come out among the people that walk\\nwith their heads downward! The Antipa'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b7c0a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " ' ',\n",
       " 'Project',\n",
       " ' ',\n",
       " 'Gutenberg',\n",
       " ' ',\n",
       " 'eBook',\n",
       " ' ',\n",
       " 'of',\n",
       " ' ',\n",
       " 'Alice',\n",
       " '’',\n",
       " 's',\n",
       " ' ',\n",
       " 'Adventures',\n",
       " ' ',\n",
       " 'in',\n",
       " ' ',\n",
       " 'Wonderland',\n",
       " ',',\n",
       " ' ',\n",
       " 'by',\n",
       " ' ',\n",
       " 'Lewis',\n",
       " ' ',\n",
       " 'Carroll',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'This',\n",
       " ' ',\n",
       " 'eBook',\n",
       " ' ',\n",
       " 'is',\n",
       " ' ',\n",
       " 'for',\n",
       " ' ',\n",
       " 'the',\n",
       " ' ',\n",
       " 'use',\n",
       " ' ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens = re.findall(r\"[a-zA-Z]+|[^a-zA-Z]\", text.lower())[1:]\n",
    "tokens = re.findall(r\"[a-zA-Z]+|[^a-zA-Z]\", text)[1:]\n",
    "# tokens = re.findall(r\"[a-zA-Z]+|[^a-zA-Z\\s]\", text)[1:]\n",
    "print(len(tokens))\n",
    "tokens[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60d62344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5bbb9989d6453d8f0ee2fab1e23244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = 15\n",
    "\n",
    "X = []\n",
    "for i in tqdm(range(len(tokens) - steps)):\n",
    "    X.append(tokens[i:i + steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c17640f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3421"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(tokens)\n",
    "\n",
    "# from collections import Counter\n",
    "# vocabulary = Counter(tokens)\n",
    "\n",
    "# from nltk.lm import Vocabulary\n",
    "# vocabulary = Vocabulary(tokens)\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a2325bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ff33d",
   "metadata": {},
   "source": [
    "# fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7550ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the vocabulary: 3,421\n",
      "Max sequence length: 16\n",
      "Embedding dimension: 32\n",
      "Feedforward dimension: 128\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 261,184\n",
      "\n",
      "encoded torch.Size([70989, 15])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf4d0afac2840a998969ff9aec07b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Epochs: 5\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0\n",
      "Epoch | Train                 | Minutes\n",
      "      | Loss     | Error Rate |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a3883cb8074dd2a51e1e00b2d16f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 |   5.7163 |     65.718 |     0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc081e47bdc4444857828cf29e5e08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 |   4.0689 |     61.193 |     0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1620235f7880470ba2de636407249e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3 |   3.6327 |     58.894 |     0.7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b23e608715c43bbb5f17d463fd4d276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 |   3.4652 |     57.896 |     0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a656cc7d0d4364bbe8083d94f9cb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 |   3.3597 |     56.890 |     1.2\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "# net = autoregressive.LSTM(vocabulary)\n",
    "net = autoregressive.TransformerEncoder(vocabulary)\n",
    "net.to(device)\n",
    "\n",
    "encoded = net.text2tensor(X)\n",
    "print(\"encoded\", encoded.shape)\n",
    "\n",
    "performance = net.fit(encoded, save_path = \"word_model.pt\")\n",
    "net.save_architecture(\"word_model.arch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce5ac70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_error_rate</th>\n",
       "      <th>training_minutes</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>model</th>\n",
       "      <th>max_sequence_length</th>\n",
       "      <th>embedding_dimension</th>\n",
       "      <th>feedforward_dimension</th>\n",
       "      <th>layers</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.716263</td>\n",
       "      <td>65.718331</td>\n",
       "      <td>0.236554</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive Transformer Encoder</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.068888</td>\n",
       "      <td>61.192579</td>\n",
       "      <td>0.471183</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive Transformer Encoder</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.632661</td>\n",
       "      <td>58.894235</td>\n",
       "      <td>0.703376</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive Transformer Encoder</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.465171</td>\n",
       "      <td>57.896294</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive Transformer Encoder</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.359733</td>\n",
       "      <td>56.890404</td>\n",
       "      <td>1.167737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoregressive Transformer Encoder</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_error_rate  training_minutes  learning_rate  \\\n",
       "0      1    5.716263         65.718331          0.236554         0.0001   \n",
       "1      2    4.068888         61.192579          0.471183         0.0001   \n",
       "2      3    3.632661         58.894235          0.703376         0.0001   \n",
       "3      4    3.465171         57.896294          0.935484         0.0001   \n",
       "4      5    3.359733         56.890404          1.167737         0.0001   \n",
       "\n",
       "   weight_decay                               model  max_sequence_length  \\\n",
       "0             0  Autoregressive Transformer Encoder                   16   \n",
       "1             0  Autoregressive Transformer Encoder                   16   \n",
       "2             0  Autoregressive Transformer Encoder                   16   \n",
       "3             0  Autoregressive Transformer Encoder                   16   \n",
       "4             0  Autoregressive Transformer Encoder                   16   \n",
       "\n",
       "   embedding_dimension  feedforward_dimension  layers  attention_heads  \\\n",
       "0                   32                    128       2                2   \n",
       "1                   32                    128       2                2   \n",
       "2                   32                    128       2                2   \n",
       "3                   32                    128       2                2   \n",
       "4                   32                    128       2                2   \n",
       "\n",
       "  activation  dropout  parameters  \n",
       "0       relu      0.0      261184  \n",
       "1       relu      0.0      261184  \n",
       "2       relu      0.0      261184  \n",
       "3       relu      0.0      261184  \n",
       "4       relu      0.0      261184  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# includes all the information about the epoch and the model, useful for reproducibility\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "102ff488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg eBook of Alice’s Adventures',\n",
       " ' Project Gutenberg eBook of Alice’s Adventures ',\n",
       " 'Project Gutenberg eBook of Alice’s Adventures in',\n",
       " ' Gutenberg eBook of Alice’s Adventures in ',\n",
       " 'Gutenberg eBook of Alice’s Adventures in Wonderland']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the input for testing\n",
    "\n",
    "net.tensor2text(encoded[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4c9a8",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3a1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the vocabulary: 3,421\n",
      "Max sequence length: 16\n",
      "Embedding dimension: 32\n",
      "Feedforward dimension: 128\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 261,184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../autoregressive.py:692: RuntimeWarning: Max sequence length exceded, only using the last 16 tokens of the input. You can disable this warning with the warn_last_tokens parameter of the forward method.\n",
      "  warnings.warn(f\"Max sequence length exceded, only using the last {self.architecture['max_sequence_length']} tokens of the input. You can disable this warning with the warn_last_tokens parameter of the forward method.\", category = RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg eBook of Alice’s Adventures,” the the” the” the”\\n\\n\\n\\n“I ',\n",
       " ' Project Gutenberg eBook of Alice’s Adventures the” the”\\n“I said the the” the”\\n“',\n",
       " 'Project Gutenberg eBook of Alice’s Adventures in,” the” the”\\n“I said the”\\n“I ',\n",
       " ' Gutenberg eBook of Alice’s Adventures in the the” the”\\n“I said the” the”\\n“',\n",
       " 'Gutenberg eBook of Alice’s Adventures in Wonderland,” the”\\n“I said the” the”\\n“I ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"word_model.arch\")\n",
    "net.load_state_dict(torch.load(\"word_model.pt\"))\n",
    "net.to(device)\n",
    "idx, log_probabilities = net.predict(encoded[:5], main_progress_bar = False, progress_bar = 0)\n",
    "\n",
    "net.tensor2text(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb6c7c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-30.1911, -31.1859, -31.7390, -31.7955, -31.9300],\n",
       "        [-32.0567, -32.1917, -32.3972, -32.5625, -32.6471],\n",
       "        [-29.4588, -30.3732, -30.5793, -31.2369, -31.2391],\n",
       "        [-33.0850, -33.4887, -33.5350, -33.5808, -33.6737],\n",
       "        [-30.1437, -30.6507, -31.1363, -31.2395, -31.4437]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ab58d",
   "metadata": {},
   "source": [
    "# greedy_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02508ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the vocabulary: 3,421\n",
      "Max sequence length: 16\n",
      "Embedding dimension: 32\n",
      "Feedforward dimension: 128\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 261,184\n",
      "\n",
      "tensor([-43.1224, -43.5087, -42.7997, -43.6141, -42.6298], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg eBook of Alice’s Adventures the the the the the the the the the the',\n",
       " ' Project Gutenberg eBook of Alice’s Adventures the the the the the the the the the the ',\n",
       " 'Project Gutenberg eBook of Alice’s Adventures in the the the the the the the the the the',\n",
       " ' Gutenberg eBook of Alice’s Adventures in the the the the the the the the the the ',\n",
       " 'Gutenberg eBook of Alice’s Adventures in Wonderland the the the the the the the the the the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"word_model.arch\")\n",
    "net.load_state_dict(torch.load(\"word_model.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.greedy_search(encoded[:5], progress_bar = False)\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd33c29",
   "metadata": {},
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc754d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the vocabulary: 3,421\n",
      "Max sequence length: 16\n",
      "Embedding dimension: 32\n",
      "Feedforward dimension: 128\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 261,184\n",
      "\n",
      "tensor([-83.7754, -65.8632, -86.6725, -80.6308, -75.7290], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg eBook of Alice’s Adventures readat tothe:tell\\ntea, being Queen with lessen.',\n",
       " ' Project Gutenberg eBook of Alice’s Adventures Alice so that\\ngive,”\\nspoke the put speaker I ',\n",
       " 'Project Gutenberg eBook of Alice’s Adventures in—said“Theyedition\\ntwinkle\\nthought\\nII bleeds\\nstop said as ',\n",
       " ' Gutenberg eBook of Alice’s Adventures in likeyou,” ways\\n _I. last givenpepper ““They',\n",
       " 'Gutenberg eBook of Alice’s Adventures in Wonderland immediately“they seemed on the go was for employeeofpaused']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"word_model.arch\")\n",
    "net.load_state_dict(torch.load(\"word_model.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.sample(encoded[:5], progress_bar = False)\n",
    "\n",
    "print(log_probabilities)\n",
    "net.tensor2text(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1efbb",
   "metadata": {},
   "source": [
    "# beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a11f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Autoregressive Transformer Encoder\n",
      "Tokens in the vocabulary: 3,421\n",
      "Max sequence length: 16\n",
      "Embedding dimension: 32\n",
      "Feedforward dimension: 128\n",
      "Layers: 2\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 261,184\n",
      "\n",
      "tensor([[-30.1911, -31.1859, -31.7390, -31.7955, -31.9300],\n",
      "        [-32.0567, -32.1917, -32.3972, -32.5625, -32.6471],\n",
      "        [-29.4588, -30.3732, -30.5793, -31.2369, -31.2391],\n",
      "        [-33.0850, -33.4887, -33.5350, -33.5808, -33.6737],\n",
      "        [-30.1437, -30.6507, -31.1363, -31.2395, -31.4437]], device='cuda:0')\n",
      "[['The Project Gutenberg eBook of Alice’s Adventures,” the the” the” the”\\n'\n",
      "  '\\n'\n",
      "  '\\n'\n",
      "  '\\n'\n",
      "  '“I ',\n",
      "  'The Project Gutenberg eBook of Alice’s Adventures,” the the” the” the” said '\n",
      "  'said said ',\n",
      "  'The Project Gutenberg eBook of Alice’s Adventures,” the the” the” the”\\n'\n",
      "  '“I I the',\n",
      "  'The Project Gutenberg eBook of Alice’s Adventures,” the the” the” the”\\n'\n",
      "  '“I said the',\n",
      "  'The Project Gutenberg eBook of Alice’s Adventures,” the the” the” the”\\n'\n",
      "  '“I I said'],\n",
      " [' Project Gutenberg eBook of Alice’s Adventures the” the”\\n'\n",
      "  '“I said the the” the”\\n'\n",
      "  '“',\n",
      "  ' Project Gutenberg eBook of Alice’s Adventures the” the”\\n'\n",
      "  '“I said the”\\n'\n",
      "  '“I I the',\n",
      "  ' Project Gutenberg eBook of Alice’s Adventures the” the”\\n'\n",
      "  '“I said the”\\n'\n",
      "  '“I said the',\n",
      "  ' Project Gutenberg eBook of Alice’s Adventures the” the”\\n'\n",
      "  '“I said the”\\n'\n",
      "  '“I I said',\n",
      "  ' Project Gutenberg eBook of Alice’s Adventures the” the”\\n'\n",
      "  '“I said the the” the”\\n'\n",
      "  '\\n'],\n",
      " ['Project Gutenberg eBook of Alice’s Adventures in,” the” the”\\n'\n",
      "  '“I said the”\\n'\n",
      "  '“I ',\n",
      "  'Project Gutenberg eBook of Alice’s Adventures in,” the” the” said said the” '\n",
      "  'the”\\n'\n",
      "  '“',\n",
      "  'Project Gutenberg eBook of Alice’s Adventures in,” the” the” said said the” '\n",
      "  'the”\\n'\n",
      "  '\\n',\n",
      "  'Project Gutenberg eBook of Alice’s Adventures in,” the” the” said said the” '\n",
      "  'the” the',\n",
      "  'Project Gutenberg eBook of Alice’s Adventures in,” the” the”\\n'\n",
      "  '“I said the the” the'],\n",
      " [' Gutenberg eBook of Alice’s Adventures in the the” the”\\n'\n",
      "  '“I said the” the”\\n'\n",
      "  '“',\n",
      "  ' Gutenberg eBook of Alice’s Adventures in the the” the”\\n“I said the”\\n“I I',\n",
      "  ' Gutenberg eBook of Alice’s Adventures in the the” the”\\n'\n",
      "  '“I said the”\\n'\n",
      "  '“I said',\n",
      "  ' Gutenberg eBook of Alice’s Adventures in the the” the”\\n'\n",
      "  '“I said the the” the ',\n",
      "  ' Gutenberg eBook of Alice’s Adventures in the the” the”\\n'\n",
      "  '“I said the the” the”'],\n",
      " ['Gutenberg eBook of Alice’s Adventures in Wonderland,” the”\\n'\n",
      "  '“I said the” the”\\n'\n",
      "  '“I ',\n",
      "  'Gutenberg eBook of Alice’s Adventures in Wonderland,” the”\\n'\n",
      "  '“I I the the” the”\\n'\n",
      "  '“',\n",
      "  'Gutenberg eBook of Alice’s Adventures in Wonderland,” the”\\n'\n",
      "  '“I I the”\\n'\n",
      "  '“I I the',\n",
      "  'Gutenberg eBook of Alice’s Adventures in Wonderland,” the”\\n'\n",
      "  '“I I the the” the”\\n'\n",
      "  '\\n',\n",
      "  'Gutenberg eBook of Alice’s Adventures in Wonderland,” the”\\n'\n",
      "  '“I I the the” the” the']]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(autoregressive)    \n",
    "net = autoregressive.load_architecture(\"word_model.arch\")\n",
    "net.load_state_dict(torch.load(\"word_model.pt\"))\n",
    "net.to(device)\n",
    "indexes, log_probabilities = net.beam_search(encoded[:5], progress_bar = False)\n",
    "\n",
    "print(log_probabilities)\n",
    "pprint([net.tensor2text(t) for t in indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4af71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
